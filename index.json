[{"content":" System Instructions are more potent than you might realize\nI have seen many posts from Network Engineers and Architects dismissing LLM’s ability to perform domain-specific tasks. While it is true that a generic LLM software like ChatGPT does not possess the same level of domain knowledge, it has a high potential to outperform humans if given proper guidance and some teaching.\nIn this post, I will cut through the noise and examine how to “teach” chatGP to answer domain-specific questions like an expert.\nNote that this article uses Cisco ACI as an example. The code used in this article can be found here — https://github.com/zhangineer/networking_llm_instruction\nThis article will guide you through the following key points:\nChatGPT’s ability to answer domain-specific questions skyrocketed when provided with quality data in small quantities.\nHuman expert knowledge in domain-specific areas is not just necessary but integral. This article will demonstrate its significance and how it can be leveraged to enhance LLM\u0026rsquo;s performance.\nMaking a helpful model requires something other than expert programming or AI/ML knowledge. The instruction-tuned approach demonstrates great potential in improving LLM’s ability to become an invaluable assistant in domain-specific technology.\nSummary Instruction-tuning greatly enhanced ChatGPT’s domain knowledge. On average, instruction-tuned ChatGPT scored 77.52%, which is 8x higher than zero-shot learning (9.53%) and ~2x higher than few-shot learning (39.72%).\nTL;DR As usual, here is a high-level summary for the busy folks:\nThis research experiment explored instruction-based tuning to enhance ChatGPT’s ability to answer domain-specific questions, specifically Cisco ACI query commands.\nThe goal was to test ChatGPT’s ability to provide accurate ACI CLI commands after being tuned with detailed instructions.\nThe Q\u0026amp;A tests contain 72 questions with three levels of difficulty. Q1–Q10 are low, Q11 — Q52 are medium, and Q53 — Q72 are high.\nThe instructions provided are similar to how we would teach a junior engineer.\nEach test was run 100 times for all 72 questions.\nIf we only account for questions answered correctly 100% of the time, the instruction-tuned model scored 56.16%, which is ~7x higher than zero-shot learning (8.22%) and few-shot learning (8.22%).\nHere is the comparison chart\nFew-shot learning results dropped sharply for questions answered correctly 100% of the time.\nI also noticed the latest Claude Opus 3 model outperforms ChatGPT4 at following instructions. However, more research and investigation are needed.\nLessons Learned Build a validation pipeline as early as possible before diving into data gathering and refining.\nConsistency is paramount. The model can answer the same question differently, but the result should always remain the same. Even getting the answer incorrectly every time, with the same answer, is better than getting the answer correctly 80% of the time.\nUse syntax highlighting if describing a syntax. It will draw attention to the model.\nCollect the error rate on every question and visualize distribution and frequency.\nKeep instructions simple. It is tempting to add as many detailed instructions as possible, but if there are overlapping languages and contexts, you risk confusing the LLM.\nAdd logic to validate both the input data and the outcome of the CLI commands. Make sure to account for dynamic output, such as timestamps.\nAvoid unnatural and tailored question prompts. These prompts may be suitable for benchmarking, but they will fail in the real world. The hardest part is accounting for different human expression styles.\nNow, let’s dive into the details.\nProblem Statement During my years building ACI data centers for customers, the most common question I received was, \u0026ldquo;How do I get XYZ information from ACI?\u0026rdquo;\nThis is because ACI SDN differs from traditional networking, requiring an understanding of its API to retrieve information efficiently.\nExample: How do I get a list of IP addresses and MAC?\nTraditional Networking: show ip arp on core router In ACI: moquery -c fvIp from one of the APICs. Note: In ACI there are also show commands available through the CLI. However, it can only retrieve the most commonly used objects. In this article, we’ll cover only the API query command - moquery\n‘moquery’ is an ACI-style CLI command that performs API calls against the APIC Managed Object (mo) database. It is a combination of a Database query and an API call. Results are returned as a Class/Object relationship, similar to Python objects.\nMy goal is to provide users with a domain-knowledge-tuned LLM that can accurately construct API commands.\nIn this article, I performed some research and experiments to see how close we can get by tuning ChatGPT with only instructions.\nBasic Terminologies instruction — In ChatGPT, instructions guide how ChatGPT should respond to prompts.\nzero-shot learning — The model has never seen the data during training and could still infer.\nfew-shot learning — Some examples are provided to the model and usually improve the model performance compared to zero-shot learning.\ninstruction-tuned (or tuned for short) — means that the model was provided detailed instructions to respond to various prompts.\nMethodology and Requirements Build QA datasets with domain knowledge. Build instructions to answer the questions from the QA dataset. Ensure data diversity to represent different real-world situations. Data must be of high quality with no errors. Implement a rigorous validation process to ensure no mistakes in score calculation. Compare the results among zero-shot learning, few-shot learning, and instruction-tuned models across various scenarios. Model used: gpt-4–1106-preview QA Questions and Tuned Instructions QA Test Questions - Link These are carefully crafted questions to test the model\u0026rsquo;s response accuracy.\nThe QA test questions are split into easy, medium, and hard difficulties based on my personal experience. There are a total of 72 questions. Q1 - Q10 (10) are easy, Q11 - Q52 (42) are medium level, and Q53 - Q72 (20) are hard. All questions are configuration-related since I only have a digital simulation of the Cisco APIC. Tuned Instruction - Link The instructions were 100% written by a human (me; last I checked, I was still human). It has four main components: basic guidelines, syntax explanations, examples, and class descriptions.\nThe system instruction is provided to ChatGPT as the first prompt for each conversation context. (as long as the context stays the same, we do not need to provide system instruction over and over)\nBasic guidelines - To instruct chatGPT on the answer format, style, limit the scope…etc. For example, Only provide an explanation if the user requests or Do not use any classes not listed in this guide\nAPI syntax explanation - Explains how the API query syntax works. For example, we start by explaining the high-level syntax:\nIndividual Class Descriptions - Each class and associated attributes provide certain information. ChatGPT must understand them and choose the correct class to answer related questions. For example, below is the description for the Bridge Domain class. (For non-ACI users/programmers, this is essentially a Python class with attributes)\nI also referenced the Cisco DevNet API class descriptions: https://developer.cisco.com/site/apic-mim-ref-api/.\nUnfortunately, we can\u0026rsquo;t pass on the entire API reference because it\u0026rsquo;s not well-written for LLM.\nFew-shot Examples - Provide ChatGPT with direct examples. These are extremely valuable and efficient but can hit diminishing returns quickly.\nFor example, the few-shot examples are provided in a Q\u0026amp;A format as shown below:\nAdditional Instructions You can also find a zero-shot and a few-shot version of the System Instructions. They are used to compare the difference between tuned and non-tuned instructions. In the end, the results show that:\nTuned instruction \u0026gt; Few-Shot \u0026gt;\u0026gt; Zero-Shot Evaluation Process To properly evaluate the answers, we perform the following:\nCompare ChatGPT\u0026rsquo;s response to the correct answer. Send ChatGPT\u0026rsquo;s response to the APIC simulator and evaluate. I\u0026rsquo;ve configured the simulator to ensure a meaningful response is always returned for each question.\nThe flow goes as follows:\nWe pass (system instructions + all 72 questions) to ChatGPT. We ask ChatGPT to provide all answers back in a single response (cost-saving) We send each ChatGPT\u0026rsquo;s CLI answer to the APIC simulator and collect the response. We also send the correct CLI answer to the APIC simulator and collect the response. We compare the responses and score each of ChatGPT\u0026rsquo;s answers. 1 point for a correct answer 0 points for an incorrect answer, but the syntax is OK -1 point for syntax error (This does not affect the total score) Repeat the above process 100 times. Below is a diagram illustration of the process\nThe Results The chart below shows that:\nOn average (blue bar), the instruction-tuned model scored 77.52%, which is ~8x higher than zero-shot learning (9.53%) and ~2x higher than few-shot learning (39.72%).\nIf we only account for questions answered correctly 100% of the time (red bar), the instruction-tuned model scored 56.16%, which is ~7x higher than zero-shot learning and ~7x higher than few-shot learning.\nBreakdown By Difficulty Levels The chart below shows that:\nThe instruction-tuned model maintained 100% accuracy in low-difficulty questions The instruction-tuned model showed minimal drops in performance between medium and high-difficulty Few-shot learning shows a tremendous jump from 0% to 43.7% score compared to zero-shot learning. The few-shot learning score drops sharply from medium to high difficulty. Now that we\u0026rsquo;ve reviewed the results, we\u0026rsquo;ll examine the process of building the validation pipeline, the pain points, and what can be improved.\nExamples Where ChatGPT Needed Hints To Interpret Q16 - Prompt Engineering Required The question is tailored so ChatGPT can interpret it correctly.\nDidn\u0026rsquo;t work: how to get a list of leafs and spines along with serial numbers and models?\nWorked: how to get a list of device serial numbers and models, excluding the controllers?\nSince there are only three types of devices in an ACI fabric, it\u0026rsquo;s common for engineers to ask with the first approach, as it is more natural.\nImagine asking someone what they had for lunch and dinner, like this: \u0026ldquo;What did you have for meals, excluding breakfast?\u0026rdquo;\nThat is not natural to me.\nChatGPT stumbles because to answer the question below,\nhow to get a list of leafs and spines along with serial numbers and models?\nOne must use the or operator instead of and. In the below query, when using and, it implies that the role of a node must be both \u0026ldquo;leaf\u0026rdquo; and \u0026ldquo;spine,\u0026rdquo; which is impossible since they are mutually exclusive.\nmoquery -c fabricNode -x 'query-target-filter=and(eq(fabricNode.role,\u0026quot;leaf\u0026quot;),eq(fabricNode.role,\u0026quot;spine\u0026quot;))'\nIn this context, how humans understand the word \u0026ldquo;and\u0026rdquo; differs from API language. The easiest approach is to use the ne(not equal) operator to exclude the APIC controller as follows:\n'query-target-filter=ne(fabricNode.role,\u0026quot;controller\u0026quot;)'\nQ28. Issues with interpretation I also had to modify the question itself\nDidn\u0026rsquo;t work - how to find a list of leafs pending for registration? Worked - how to find a list of devices pending for registration that are also leaf switches I am somewhat surprised that ChatGPT couldn\u0026rsquo;t understand the question. Without hints ChatGPT will answer as follows:\nmoquery -c dhcpClient -x 'query-target-filter=eq(dhcpClient.clientEvent,\u0026quot;pending\u0026quot;)'\nCorrect answer:\nmoquery -c dhcpClient -x 'query-target-filter=and(eq(dhcpClient.clientEvent,\u0026quot;pending\u0026quot;),eq(dhcpClient.configNodeRole,\u0026quot;leaf\u0026quot;))'\nChatGPT did not understand the question and missed out on the fact that we were only interested in the leaf devices.\nQ15. Vague class description This one is more of a human error. Here is the question:\nHow to find the fabric TEP address pool?\ntepPool is an attributes of the class topSystem, and our goal is to find its value. Hence, we need to query for other fields of the same class. To get the value, one can query either Spine, Leaf, or Controller.\nAs shown below, I intended for ChatGPT to use the role attribute as a filter to find tepPool information from the same object.\n### topSystem: device state and configuration information class * `role`: role of the device, available options are: `controller`, `leaf`, `spine` * `tepPool`: fabric TEP address pool for the whole system, example: `10.0.0.0/16` Correct answer:\nmoquery -c topSystem -x 'query-target-filter=eq(topSystem.role,\\\u0026quot;controller\\\u0026quot;)\nChatGPT will get it correct sometimes, but other times, it\u0026rsquo;ll give me something like this:\nmoquery -c topSystem -x 'query-target-filter=ne(topSystem.tepPool,\u0026quot;\u0026quot;)'\nNote the empty values (\u0026quot;\u0026quot;) in the filter implies that ChatGPT realizes that it\u0026rsquo;s an unknown value and we need to find it, but the ACI API doesn\u0026rsquo;t support empty string matching.\nThe vague part is in the description of the class itself.\nDidn\u0026rsquo;t work - topSystem: system information class Worked - topSystem: device state and configuration information class Human guidance is vital in guiding LLMs, similar to providing knowledge to another human.\nObservations The following observations are not inclusive; there are probably more than I can remember.\nThe Good Great potential and simplified user experience. There is much less code to write compared to using function calls. Instruction-tuning can cover a lot more use cases than function calls. Even engineers with no coding skills can help contribute with their expert knowledge. The Bad The model is susceptible to minor adjustments, even if you set the temperature to 0. Sometimes, changing a symbol or deleting a word can impact its performance\nThe model never tells if you made grammatical errors; you only see them in the results, which means extensive version controls (do you really want to version control every letter or symbol change?)\nSometimes, you need to use tailored prompts/question styles so the model can better understand it.\nThe tuned model requires more tokens (~4x compared to zero-shot) and will continue expanding to cover more use cases. A larger context is more expensive.\nUnlike programming languages that are \u0026ldquo;mostly\u0026rdquo; deterministic, LLMs aren\u0026rsquo;t. They have wild thoughts, memories, and knowledge, so they might want to be a bit creative, which is exactly what we DON\u0026rsquo;T NEED in networking !!\nImagine, during an SAT exam, a student crosses out one of the multiple answers and adds her own answer (creativity in exchange for a point? I don\u0026rsquo;t think so!)\nThe Ugly The model result is inconsistent.\nOccasionally, you\u0026rsquo;ll see the model answer the same question correctly 50% of the time or even 99% of the time. (Four questions were answered correctly 99/100 times.) This makes tuning extremely challenging. (RLHF can potentially help here; I provided no feedback to the model.)\nImagine never telling students which question they got correct on an exam and expecting them to achieve 100% by brute force, forcing them to retake exams; good luck with that!\nThe model still hallucinates as usual.\nThe model can be stuck with past memory.\nDuring training, if one type of data appears too frequently, the model will not easily forget that, no matter how \u0026ldquo;bad\u0026rdquo; that memory was. Scalability Considerations To efficiently scale this deployment, we may consider the following approaches:\nIncorporate RAG - However, this means another level of dependency on the retrieval process\u0026rsquo;s accuracy. Additionally, as LLMs context windows get larger and even infinite context windows, the use of RAG will diminish.\nMulti-agent - Each agent is responsible for one area of knowledge. (hardware query vs. routing table query).\nFine-tuning - Tune the weights with new training data so the model can answer questions without extra instructions. However, be aware of catastrophic forgetting.\nHybrid - Mix instruction tuning with the function-calling feature.\nInstruction Tuning Pros and Cons Pros Tuned using human natural language Expert knowledge of LLMs is optional as long as the pipeline is built. Easy to iterate, update, and expand as needed Cons Additional efforts are required to convert vendor documents if they aren\u0026rsquo;t well-written It is costly if the software backend isn\u0026rsquo;t well designed to scale Context window limit It\u0026rsquo;s difficult to debug because it\u0026rsquo;s all natural language based. Machines still don\u0026rsquo;t quite understand words the same way humans do. Additional Tests To Consider My testing pipeline only contains questions that should always yield a command as the answer. Additional testing cases to be considered:\nTest the model\u0026rsquo;s ability to respond with \u0026ldquo;insufficient information\u0026rdquo; when no specific class definition is given to reduce hallucinations Test the model\u0026rsquo;s ability to explain the result when requested by the user Test the model\u0026rsquo;s ability to quote the object definition where it is referenced Test the model\u0026rsquo;s ability to respond to the same question but asked in different ways Accuracy Improvements and Alternatives Compare against different models, such as Claude 3 Opus 3, LLaMA3, or Mistral, to see if a better model exists, or even vote among various models for the best results. Try a model built explicitly for instruction tuning, such as the FLAN-T5 model. Try using another model to help tune instructions iteratively and automatically based on testing results. *Expand testing datasets to include operational tasks and queries From This Point On, It's All About The Technical Details Tuned Instructions Explained in Details In this section, we\u0026rsquo;ll review some of the details and intricacy of the tuned instructions and their effects on the outcome, for better or worse.\nRole Definition You are a co-pilot to the network engineers. * Your responsibilities are to provide assistance to network engineer in constructing Cisco ACI queries and execute commands * Do not provide commands or information that was not provided to you in this instruction * Respond with only the command, do not add any descriptions * Only provide explanation if the user requested * You do not ever apologize and strictly generate networking commands based on the provided examples. * Do not provide any networking commands that can\u0026#39;t be inferred from the instructions * Inform the user when you can\u0026#39;t infer the networking command due to the lack of context of the conversation and state what is the missing in the context. * Do not use any classes not listed in this guide * Do not include \u0026#34;`\u0026#34; symbols in your response * Make sure to review the examples before building the final query * For each question, make sure to always identify the parent class and the children class first, if applicable. * If reverse lookup is needed, make sure to follow the \u0026#34;Reverse Lookup Technique\u0026#34; approach * The following are syntax to construct ACI queries, think step by step to build the query. * Before constructing a query, make sure to carefully review all details of a given class description The role definition helps in the following areas:\nProvides context to control what types of questions to answer. Help increase accuracy in more complex queries, such as using the classic \u0026ldquo;think step by step\u0026rdquo; technique. Control response format - LLMs, by default, are verbose and sometimes will respond with backticks as well as in a code block, which we do not want to include Syntax Format The general format of a Cisco ACI query command is structured as follows: `moquery -c \u0026lt;class1\u0026gt;,\u0026lt;class2\u0026gt;,\u0026lt;class2\u0026gt; -x \u0026lt;option1\u0026gt; \u0026lt;option2\u0026gt; \u0026lt;option3\u0026gt;`...etc. * we only need to specify `-x` once, even for multiple options. * the format `\u0026lt;class1\u0026gt;,\u0026lt;class2\u0026gt;,\u0026lt;class3\u0026gt;` is called multi-class query. It will return all objects for the matching class name. * query-target-filter: filter based on query class, general format: `\u0026#39;\u0026lt;operator\u0026gt;(\u0026lt;filter\u0026gt;)\u0026#39;`, where `filter` looks like this `\u0026lt;class\u0026gt;.\u0026lt;attribute\u0026gt;,\u0026#34;value_to_filter\u0026#34;` * example: `moquery -c \u0026lt;class\u0026gt; -x \u0026#39;query-target-filter=eq(\u0026lt;class\u0026gt;.\u0026lt;attribute\u0026gt;,\u0026#34;value_to_filter\u0026#34;)\u0026#39;` * never use multiple `query-target-filter` option * available operators are: 1. `eq`: equal 2. `ne`: not equal 3. `gt`: greater than, only applies to numerical values 4. `wcard`: wild card or contains 5. `bw`: between 2 numerical values or time stamps 6. `ge`: greater than or equal to 7. `le`: less than or equal to 8. `lt`: less than, only applies to numerical values 9. `or`: or 10. `and`: and * rsp-subtree: Specifies child object level included in the response, valid values are: `no | children | full` * rsp-subtree-class: Respond only specified classes in the subtree. * rsp-subtree-filter: Respond only if the subtree classes matching conditions * rsp-subtree-include: Request additional objects in the subtree - `required`. If `rsp-subtree-class` option is used, we should always add the `required` option. - `no-scoped` Response includes only the requested subtree information. Useful for getting faults related to an object. * query-target: restricts the scope of the query. valid options are `self(default) | children | subtree` * order-by: Sort the response based on the property values, valid values are `asc (ascending) | desc(descending)` * page-size: return a limited number of results For consistency purposes, I provided only the API syntax to ChatGPT. (there is also a format using moquery -c -f , for example, moquery -c fvAEPg -f \u0026lsquo;fv.AEPg.pcTag==\u0026ldquo;xxxx\u0026rdquo;\u0026rsquo;.)\nNot all syntax formats are provided; these cover the most common usages\nReverse Lookup Technique ## Reverse Lookup Technique If user asks to get parent object based a child object, we need to perform reverse lookup. `moquery -c \u0026lt;parent_class\u0026gt; -x rsp-subtree-class=\u0026lt;child_class\u0026gt; rsp-subtree-include=required rsp-subtree=children \u0026#39;rsp-subtree-filter=eq(\u0026lt;child_class\u0026gt;.\u0026lt;attribute\u0026gt;,\u0026#34;value_to_match\u0026#34;)\u0026#39;` Explanation: * `rsp-subtree-class` defines what the child class we want to target * `rsp-subtree-include=required` ensures that we return parent object only if the child object class exist ( this should always be used by default in most cases ) * `rsp-subtree=children` returns all the children objects * `rsp-subtree-filter` applies the filter, note that we use child_class here. This section is created to answer complex questions requiring a reverse lookup (i.e., given the child\u0026rsquo;s object, find the parent\u0026rsquo;s attributes).\nChatGPT cannot derive such understanding on its own if it is only provided a description of each option flag. Spelling out special instructions, if needed, is critical, highlighting the importance of human guidance.\nBoth zero-shot and few-shot models performed poorly in this area\nExample With Explanation Assuming that you are provided the following class information ``` ### fvTenant: Tenant class * `name`: name of the Tenant * CHILDREN CLASSES: - `fvAp`: Application Profile class - `name`: name of the application profile - CHILDREN CLASSES: - `fvAEPg`: EPG class - `name`: name of the EPG - `fvBD`: Bridge Domain class - `name`: name of the bridge domain - CHILDREN CLASSES: \u0026lt;\u0026lt;\u0026lt;\u0026lt; Nested children class - `fvSubnet`: Subnet class - `ip`: ip subnet, example \u0026#34;10.0.0.1/24\u0026#34; ``` * To get the Tenant named `example_tenant` with no additional children information: `moquery -c fvTenant -x \u0026#39;query-target-filter=eq(fvTenant.name,\u0026#34;example_tenant\u0026#34;)` * To get a list of AP in Tenant `example_tenant`: `moquery -c fvTenant -x \u0026#39;query-target-filter=eq(fvTenant.name,\u0026#34;example_tenant\u0026#34;) rsp-subtree-class=fvAp rsp-subtree=children` * To get a list of EPGs in Tenant `example_tenant`: `moquery -c fvTenant -x \u0026#39;query-target-filter=eq(fvTenant.name,\u0026#34;example_tenant\u0026#34;)\u0026#39; rsp-subtree-class=fvAEPg rsp-subtree=full rsp-subtree-include=required` * To get the EPG named `my_epg` in tenant `example_tenant`, we need to perform a reverse lookup with a filter: `moquery -c fvTenant -x rsp-subtree-class=fvAEPg rsp-subtree=full rsp-subtree-include=required \u0026#39;query-target-filter=eq(fvAEPg.name,\u0026#34;my_epg\u0026#34;)` * To find all BD and APs of Tenant `example_tenant`, use comma to separate multiple classes query: `moquery -c fvTenant -x rsp-subtree-class=fvAp,fvBD rsp-subtree=children \u0026#39;query-target-filter=eq(fvTenant.name,\u0026#34;example_tenant\u0026#34;)\u0026#39;` * To get all the faults related to Tenant `example_tenant`: `moquery -c fvTenant -x rsp-subtree-include=faults,no-scoped query-target=subtree` * To get a list of Tenants and associated EPGs, excluding any Tenant named `common`: `moquery -c fvTenant -x rsp-subtree=full \u0026#39;query-target-filter=ne(fvTenant.name,\u0026#34;common\u0026#34;) rsp-subtree-class=fvAEPg rsp-subtree-include=required\u0026#39;` **note** we use `rsp-subtree=full` if the children class is more than 2 layers down from the parent object The above helps \u0026ldquo;explain\u0026rdquo; to ChatGPT how to interpret the class object structure. The goal was to solve the problem of ChatGPT not being able to follow nested objects properly. However, this approach resulted in little improvements (ChatGPT was able to answer some of the advanced questions with nested objects correctly, but is still inconsistent)\nQ\u0026amp;A Examples ## Q\u0026amp;A Examples: Here are some moquery examples: * how to get a list of BDs in tenant common? `moquery -c fvBD -x \u0026#39;query-target-filter=wcard(fvBD.dn,\u0026#34;/tn-common/\u0026#34;)\u0026#39;` * how to get the BD with the exact name of either \u0026#34;customer\u0026#34; or \u0026#34;cust\u0026#34;, regardless of which tenant they belong to? `moquery -c fvBD -x \u0026#39;query-target-filter=or(eq(fvBD.name,\u0026#34;customer\u0026#34;),eq(fvBD.name,\u0026#34;cust\u0026#34;))\u0026#39;` * how to get all BDs with unicast routing disabled in Tenant common? `moquery -c fvBD -x \u0026#39;query-target-filter=and(wcard(fvBD.dn,\u0026#34;/tn-common/\u0026#34;),eq(fvBD.unicastRoute,\u0026#34;no\u0026#34;))\u0026#39;` * how to get all BDs that has a subnet configured? `moquery -c fvBD -x rsp-subtree-class=fvSubnet rsp-subtree=children rsp-subtree-include=required` * how to get all BDs that has a subnet configured, and the subnet must also route leak? `moquery -c fvBD -x rsp-subtree-class=fvSubnet rsp-subtree=children rsp-subtree-include=required \u0026#39;rsp-subtree-filter=eq(fvSubnet.scope,\u0026#34;shared\u0026#34;)\u0026#39;` * how to get a list of static path bindings tagged with VLAN 1? `moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=and(eq(fvRsPathAtt.encap,\u0026#34;vlan-1\u0026#34;),eq(fvRsPathAtt.mode,\u0026#34;regular\u0026#34;))\u0026#39;` * how to get a list of static path bindings tagged with VLAN 10? `moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=and(eq(fvRsPathAtt.encap,\u0026#34;vlan-10),eq(fvRsPathAtt.mode,\u0026#34;regular\u0026#34;))\u0026#39;` * how to get a list of path bindings tagged with VLAN 50? `moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=and(eq(fvRsPathAtt.encap,\u0026#34;vlan-50),eq(fvRsPathAtt.mode,\u0026#34;regular\u0026#34;))\u0026#39;` * how to get a list of static path bindings in VLAN 5? `moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=eq(fvRsPathAtt.encap,\u0026#34;vlan-5\u0026#34;)\u0026#39;` * how to get a list of static path bindings for leaf 101 and leaf 102, interface 1/24 assuming that this interface is not part of vPC or PC? `moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=wcard(fvRsPathAtt.dn,\u0026#34;paths-101/pathep-\\[eth1/4\\]\u0026#34;)\u0026#39;` * how to get all the bridge domains, ordered by modification date, latest first, return only the top 1st result? `moquery -c fvBD -x page-size=1 page=0 order-by=\u0026#39;fvBD.modTs|desc\u0026#39;` * how to get all configuration changes made to tenant \u0026#34;demo\u0026#34; between time 2023/12/21 5 AM and 202/12/30 9 PM? `moquery -c aaaModLR -x \u0026#39;query-target-filter=and(bw(aaaModLR.created,\u0026#34;2023-12-21T05:00\u0026#34;,\u0026#34;2023-12-30T21:00\u0026#34;),wcard(aaaModLR.affected,\u0026#34;tn-demo/\u0026#34;))\u0026#39;` * how to find configurations with specifically `deleted` action by user admin between 2024-02-08 and 2024-02-10? `moquery -c aaaModLR -x \u0026#39;query-target-filter=and(eq(aaaModLR.ind,\u0026#34;deletion\u0026#34;),eq(aaaModLR.user,\u0026#34;admin\u0026#34;),bw(aaaModLR.created,\u0026#34;2024-02-01\u0026#34;,\u0026#34;2024-02-15\u0026#34;))\u0026#39;` * how to find out how many Bridge Domain objects there are? `moquery -c fvBD -x rsp-subtree-include=count` * how to get a list of BDs associated with vrf \u0026#34;demo_vrf\u0026#34;? `moquery -c fvBD -x rsp-subtree-class=fvRsCtx rsp-subtree=children rsp-subtree-include=required \u0026#39;rsp-subtree-filter=eq(fvRsCtx.tnFvCtxName,\u0026#34;demo_vrf\u0026#34;)\u0026#39;` * how to find all the consumers and providers of contract \u0026#34;application_contract\u0026#34;? `moquery -c fvAEPg -x rsp-subtree=children rsp-subtree-class=fvRsProv,fvRsCons rsp-subtree-include=required \u0026#39;rsp-subtree-filter=or(eq(fvRsProv.tnVzBrCPName,\u0026#34;application_contract\u0026#34;),eq(fvRsCons.tnVzBrCPName,\u0026#34;application_contract\u0026#34;))\u0026#39;` LLMs typically use the above example format for fine-tuning and few-shot learnings. ChatGPT had issues interpreting the meaning of tagged with and in for VLANs; hence, the same example was repeated. Providing examples like these is highly effective compared to zero-shot models; however, examples alone are insufficient to achieve higher accuracy. Individual Class Object Descriptions Below, I have listed only the high-level summary and the first class. The remaining class description structure repeats.\n## Frequently Used Classes and Attributes Layout * The following describes the attributes for each class. * Many classes have children classes as well. and each children class also has their own attributes. - Children classes can be directly queried, or it can be included when querying against a parent class using option `-x rsp-subtree=children` - For nested children class, use `-x rsp-subtree=full` * `dn` is a universal attribute available to all classes, it means distinguished name * Every class has an attribute of `dn`, but not all are included as they are pretty obvious. * values in `( )` defines available options if not specifically called out. ### fvBD: Bridge Domain Class **note**: there are default bridge domains already-exists and we typically want to exclude them from queries, their names are: `default`,`ave-ctrl`, and `inb` * `name`: name of a bridge domain * `dn` example: `uni/tn-demo/BD-demo_web_bd` * `mac`: MAC address of the bridge domain, default = 00:22:BD:F8:19:FF * `hostBasedRouting(yes/no)`: whether host based routing is enabled or not. * `unicastRoute(yes/no)`: The forwarding method based on predefined forwarding criteria (IP or MAC address), default = yes * `unkMacUcastAct(flood/proxy)`: The forwarding method for unknown layer 2 destinations, default = proxy * `limitIpLearnToSubnets(yes/no)`: limit ip learning to subnet only or not, default = no * `arpFlood(yes/no)`: whether arp flood is enabled or not, we should automatically exclude default BDs when user asks for this. * `descr`: description of the bridge domain * CHILDREN CLASSES: - `fvSubnet`: class for subnets under a bridge domain * `ip`: subnet * `scope(public/shared/private)`: `public` = advertised out, `shared` = route leaking, `private` = not advertised out. In addition to individual options, you can also join them with comma, available combinations are: `public,shared`, `private,shared` - `fvRsBDToOut`: class related to Bridge Domain, for L3Out * `tnL3extOutName`: name of the L3Out associated with the bridge domain * `dn` example: uni/tn-demo/BD-demo_bd/rsBDToOut-demo_l3out - `fvRsCtx`: class related to Bridge Domain, for VRF * `tnFvCtxName`: name of the vrf associated with the bridge domain * `dn` example: uni/tn-demo/BD-demo_web_bd/rsctx A high-level summary briefly explains the structure of classes and the format that I use to suggest how to interpret them.\nThis line is another reminder to ChatGPT that for nested child class, use a different flag - For nested children class, use -x rsp-subtree=full\nThe header for the class name and a short description - ### fvBD: Bridge Domain Class. This information is critical for ChatGPT to know which class to use for a given query before diving into the attributes.\nThe **note section helps highlight important information. This worked very well with Claude, but it\u0026rsquo;s hit or miss with ChatGPT.\nI manually created each object description, aligning it with my understanding. I also referenced Cisco\u0026rsquo;s official document when needed.\nNot every attribute is listed for two reasons: to reduce hallucinations and control ChatGPT\u0026rsquo;s knowledge scope.\nObjects descriptions could use more improvements, such as this sub-class: `fvRsBDToOut`: class related to Bridge Domain, for L3Out. The reason that it\u0026rsquo;s described seemingly backward is because I noticed that ChatGPT will pick up L3out as a cue first if it\u0026rsquo;s described like this `fvRsBDToOut`: L3Out relationship class associated with Bridge Domain, which leads to ChatGPT thinking that this is for L3Out.\nAgain, the object relationship and nesting concept described here are challenges for ChatGPT to grasp. (It\u0026rsquo;s also possible that I haven\u0026rsquo;t found the perfect English words to describe it)\nThe values inside () are for ChatGPT to understand all available options; some are straightforward, and others aren\u0026rsquo;t. Therefore, an extra description of each option is required. For example:\nscope(public/shared/private): `public` = advertised out, `shared` = route leaking, `private` = not advertised out. In addition to individual options, you can also join them with comma, available combinations are: `public,shared`, `private,shared` An engineer might ask something like, \u0026ldquo;What are the routes advertised out and leaked?\u0026rdquo; instead of \u0026ldquo;What are the public and shared routes?\u0026rdquo; Keep in mind that user prompts will influence ChatGPT, but from a UX/UI perspective, we should minimize such an effect.\nIndividual Question Analysis The following chart shows chatGPT\u0026rsquo;s weaknesses with the tuned instructions. We\u0026rsquo;ll take a deeper look at some of the questions that even the instruction-tuned model failed miserably and see if we can gain some insights to understand better how we might be able to address them.\nQ15 (Score 51%) - Bug in the pipeline (not 100% the model\u0026rsquo;s fault) Below is the partial ACI response from the Q15 command for both the correct answer and ChatGPT\u0026rsquo;s answer.\nQuestion: Q15. how to find the fabric TEP address pool 2024-04-21 21:51:37,075 - __main__ - INFO - correct answer cmd: moquery -c topSystem -x \u0026#39;query-target-filter=eq(topSystem.role,\u0026#34;controller\u0026#34;)\u0026#39; 2024-04-21 21:51:37,075 - __main__ - INFO - gpt answer cmd: moquery -c topSystem -x \u0026#39;query-target-filter=wcard(topSystem.dn,\u0026#34;/pod-\u0026#34;)\u0026#39; 2024-04-21 21:51:38,963 - __main__ - INFO - correct cmd output: { \u0026#34;totalCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;imdata\u0026#34;: [ { \u0026#34;topSystem\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;10.0.0.1\u0026#34;, \u0026#34;bootstrapState\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;childAction\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;clusterTimeDiff\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;configIssues\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;controlPlaneMTU\u0026#34;: \u0026#34;9000\u0026#34;, \u0026#34;currentTime\u0026#34;: \u0026#34;2024-04-21T21:51:30.922+00:00\u0026#34;, \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; \u0026lt; SNIP \u0026gt; 2024-04-21 21:51:38,963 - __main__ - INFO - chatGPT cmd output: { \u0026#34;totalCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;imdata\u0026#34;: [ { \u0026#34;topSystem\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;10.0.0.1\u0026#34;, \u0026#34;bootstrapState\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;childAction\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;clusterTimeDiff\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;configIssues\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;controlPlaneMTU\u0026#34;: \u0026#34;9000\u0026#34;, \u0026#34;currentTime\u0026#34;: \u0026#34;2024-04-21T21:51:31.879+00:00\u0026#34;, \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; \u0026lt; SNIP \u0026gt; This question is sometimes marked incorrectly because there is a currentTime element that changes each time we make a query.\nSo, in this case, it was a bug in the validation pipeline; ChatGPT\u0026rsquo;s score probably should\u0026rsquo;ve been higher.\nPotential Solution: Skip comparing results/fields that will change per query. Evaluating answers based on a specific format is not a good approach. ChatGPT can sometimes surprise you with its response.\nBut wait, what about the other 49% of the times that it was correct? Since the time element changes each time, shouldn\u0026rsquo;t it be wrong 100% of the time?\nBecause we have a logic that checks for the commands first, and if it\u0026rsquo;s 100% matched, we do not need to compare the output, as shown below\nQuestion: Q15. how to find the fabric TEP address pool 2024-04-21 21:48:30,038 - __main__ - INFO - correct answer cmd: moquery -c topSystem -x \u0026#39;query-target-filter=eq(topSystem.role,\u0026#34;controller\u0026#34;)\u0026#39; 2024-04-21 21:48:30,038 - __main__ - INFO - gpt answer cmd: moquery -c topSystem -x \u0026#39;query-target-filter=eq(topSystem.role,\u0026#34;controller\u0026#34;)\u0026#39; 2024-04-21 21:48:30,038 - __main__ - INFO - command is 100% matched If ChatGPT had been more consistent, we wouldn\u0026rsquo;t have discussed Q15.\nQ18: Class/Attribute Confusion Question: Q18. how to get a list of subnets advertised out and also route leaked different filter used 2024-04-21 21:45:17,112 - __main__ - INFO - correct answer cmd: moquery -c fvSubnet -x \u0026#39;query-target-filter=eq(fvSubnet.scope,\u0026#34;public,shared\u0026#34;)\u0026#39; 2024-04-21 21:45:17,112 - __main__ - INFO - gpt answer cmd: moquery -c fvSubnet -x \u0026#39;query-target-filter=wcard(fvSubnet.scope,\u0026#34;public,shared\u0026#34;)\u0026#39; incorrect syntax 2024-04-21 21:38:53,470 - __main__ - INFO - correct answer cmd: moquery -c fvSubnet -x \u0026#39;query-target-filter=eq(fvSubnet.scope,\u0026#34;public,shared\u0026#34;)\u0026#39; 2024-04-21 21:38:53,470 - __main__ - INFO - gpt answer cmd: moquery -c fvSubnet -x \u0026#39;query-target-filter=or(eq(fvSubnet.scope,\u0026#34;export-rtctrl\u0026#34;),eq(fvSubnet.scope,\u0026#34;shared-rtctrl\u0026#34;))\u0026#39; In the first response, ChatGPT\u0026rsquo;s used a wcard filter instead of eq, which is fine but not ideal. Frankly, in this specific case, eq and wcard made no difference.\nIn the second response, ChatGPT provided an invalid syntax.\nHere is the fvSubnet class:\n### fvBD: Bridge Domain Class * `name`: name of a bridge domain \u0026lt;SNIP\u0026gt; * CHILDREN CLASSES: - `fvSubnet`: class for subnets under a bridge domain * `ip`: subnet * `scope(public/shared/private)`: `public` = advertised out, `shared` = route leaking, `private` = not advertised out. In addition to individual options, you can also join them with comma, available combinations are: `public,shared`, `private,shared` There are no export-rtctrl or shared-rtctrl attributes, so where did ChatGPT get them from?\nThey are from the L3Out class description, as shown below; l3extSubnet (child class of L3Out) contains attributes with the same name, ip, and scope, but ChatGPT should\u0026rsquo;ve followed the class name first. It is also possible that ChatGPT picked up the description of scope of the subnet prefix without awareness of the context.\nThis implies that ChatGPT doesn\u0026rsquo;t always understand the class/attribute hierarchy. We\u0026rsquo;ll see more of these later.\n### l3extOut: layer3 out (L3out) class * `name`: name of the L3Out profile * CHILDREN CLASSES: - `l3extInstP`: L3out EPG - `dn` example: `uni/tn-demo/out-demo_l3out/instP-demo_l3out_epg` - `prefGrMemb(include/exclude)`: Preferred group member - CHILDREN CLASSES: - `l3extSubnet`: This class is for L3Out EPG prefixes - `ip`: prefix IP address. e.g. `0.0.0.0/0` - `scope`: scope of the subnet prefix, available options are `export-rtctrl`, `import-security`, `shared-rtctrl`, `shared-security`, can be combined. `import-security` is the default. - `aggregate`: whether aggregate options are used, available options are `export-rtctrl` and `shared-rtctrl`, can be combined. Potential Solution: Emphasize the importance of the class, attribute, and children\u0026rsquo;s class hierarchy in syntax description. Provide more distinctive descriptions when attribute names overlap across different classes.\nQ21 - Prompt Issue and Concept Confusion Q: How to get a list of BDs excluding the default ones?\nBelow are examples of ChatGPT\u0026rsquo;s answer in 2 different instances, which unveils two potential issues.\nQuestion: Q21. how to get a list of BDs excluding the default ones 2024-04-21 21:51:40,927 - __main__ - INFO - correct answer cmd: moquery -c fvBD -x \u0026#39;query-target-filter=and(ne(fvBD.name,\u0026#34;inb\u0026#34;),ne(fvBD.name,\u0026#34;ave-ctrl\u0026#34;),ne(fvBD.name,\u0026#34;default\u0026#34;))\u0026#39; 2024-04-21 21:51:40,928 - __main__ - INFO - gpt answer cmd: moquery -c fvBD -x \u0026#39;query-target-filter=ne(fvBD.name,\u0026#34;default\u0026#34;) ne(fvBD.name,\u0026#34;ave-ctrl\u0026#34;) ne(fvBD.name,\u0026#34;inb\u0026#34;)\u0026#39; 2024-04-21 21:48:31,942 - __main__ - INFO - Question: Q21. how to get a list of BDs excluding the default ones 2024-04-21 21:48:31,942 - __main__ - INFO - correct answer cmd: moquery -c fvBD -x \u0026#39;query-target-filter=and(ne(fvBD.name,\u0026#34;inb\u0026#34;),ne(fvBD.name,\u0026#34;ave-ctrl\u0026#34;),ne(fvBD.name,\u0026#34;default\u0026#34;))\u0026#39; 2024-04-21 21:48:31,942 - __main__ - INFO - gpt answer cmd: moquery -c fvBD -x \u0026#39;query-target-filter=ne(fvBD.name,\u0026#34;default\u0026#34;)\u0026#39; Issue #1 - Prompt not specific enough or lack of comprehension\nThe answer in the first example has invalid syntax. However, when I reviewed the answer to a similar question, ChatGPT scored higher! As shown below:\nQ25: how to get a list of BDs with ARP flooding disabled, excluding default BDs\nThis answer required an additional filter and queried against the same class - fvBD. The overall score for this question is 87%\n2024-04-21 21:42:07,231 - __main__ - INFO - Question: Q25. how to get a list of BDs with ARP flooding disabled, excluding default BDs 2024-04-21 21:42:07,231 - __main__ - INFO - correct answer cmd: moquery -c fvBD -x \u0026#39;query-target-filter=and(eq(fvBD.arpFlood,\u0026#34;no\u0026#34;),ne(fvBD.name,\u0026#34;inb\u0026#34;),ne(fvBD.name,\u0026#34;ave-ctrl\u0026#34;),ne(fvBD.name,\u0026#34;default\u0026#34;))\u0026#39; 2024-04-21 21:42:07,231 - __main__ - INFO - gpt answer cmd: moquery -c fvBD -x \u0026#39;query-target-filter=and(ne(fvBD.name,\u0026#34;default\u0026#34;),ne(fvBD.name,\u0026#34;ave-ctrl\u0026#34;),ne(fvBD.name,\u0026#34;inb\u0026#34;),eq(fvBD.arpFlood,\u0026#34;no\u0026#34;))\u0026#39; Issue #2 - ChatGPT is confused with the term \u0026ldquo;default\u0026rdquo; in some contexts.\n\u0026ldquo;setting named default\u0026rdquo; is different from \u0026ldquo;default settings.\u0026rdquo; The former refers to a specific setting that uses the name \u0026ldquo;default,\u0026rdquo; and the latter could refer to multiple settings that were never changed.\nAs shown below\nThis is correct:\nmoquery -c fvBD -x 'query-target-filter=and(ne(fvBD.name,\u0026quot;inb\u0026quot;),ne(fvBD.name,\u0026quot;ave-ctrl\u0026quot;),ne(fvBD.name,\u0026quot;default\u0026quot;))'\nThis is incorrect\nmoquery -c fvBD -x 'query-target-filter=ne(fvBD.name,\u0026quot;default\u0026quot;)'\nPotential Solution: Rephrase the question and differentiate these two concepts with more diversified examples.\nAdditionally, with some step-by-step prompts, ChatGPT knows how to answer this question. It\u0026rsquo;s frustrating that it didn\u0026rsquo;t answer correctly on the first try, resulting in a bad user experience.\nSide note: I tried the same in Claude Opus3, and it got the answer correctly on the first try! Maybe I\u0026rsquo;ll write a blog on Claude next to compare performance.\nQ35 - Hallucination This question is a bit tricky because the EPG object path is tn-Tenant/ap-ANP/epg-EPG , and AP information was not given, so we need to perform a wcard match on the Tenant name and EPG name at the same time.\nAs shown below, ChatGPT essentially made up the AP name when the AP information was not given.\nQ35. how to get a list of path bindings in EPG epg_vlan0005 in tenant demo correct answer cmd: moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=and(wcard(fvRsPathAtt.dn,\u0026#34;epg-epg_vlan0005/\u0026#34;),wcard(fvRsPathAtt.dn,\u0026#34;tn-demo/\u0026#34;))\u0026#39; gpt answer cmd: moquery -c fvRsPathAtt -x \u0026#39;query-target-filter=wcard(fvRsPathAtt.dn,\u0026#34;/tn-demo/ap-demo_anp/epg-epg_vlan0005/\u0026#34;)\u0026#39; Potential Solution: Try adding more specific examples to illustrate the use of concatenating wildcard-based matches.\nQ31 \u0026amp; Q32 - Preposition Words A particularly interesting issue I encountered was that ChatGPT couldn\u0026rsquo;t grasp the difference between \u0026ldquo;tagged with VLAN 5\u0026rdquo; vs. \u0026ldquo;in VLAN 5\u0026rdquo;.\nNetwork engineers know that the former refers to VLAN tagging, and the latter is more generic regardless of the port configuration mode. This is the same in ACI.\nThough both Q31 and Q32 had perfect scores, it was largely due to my extra effort to ensure that ChatGPT could distinguish between them. This is still a potential issue that will require more tuning.\nAs shown below, I have used several examples of the same question to emphasize the difference.\nQ39 - Unable to Comprehend Hierarchical Nested Object Definitions Given the following object descriptions and questions:\nPay attention to where the action(permit/deny) is applied for a filter.\n### vzBrCP: Contract class * `name`: name of the contract * CHILDREN CLASSES: - `vzSubj`: Contract subject class - `name`: name of the subject - CHILDREN CLASSES: - `vzRsSubjFiltAtt`: class related to the subject, for filters - `tnVzFilterName`: name of the filter - `action(permit/deny)`: action of the filter. ### vzFilter: Filter class * `name`: name of the filter * CHILDREN CLASSES: - `vzEntry`: Filter entry class. Multiple filter entries can be associated with a filter - `name`: name of the filter entry - `dFromPort`: starting port number - `dToPort`: end port number - `protocol(tcp/udp/icmp)`: protocol for the filter entry. Question: how to get a list of filters with permit actions?\ncorrect answer cmd: moquery -c vzRsSubjFiltAtt -x \u0026#39;query-target-filter=eq(vzRsSubjFiltAtt.action,\u0026#34;permit\u0026#34;)\u0026#39; gpt answer cmd: moquery -c vzFilter -x \u0026#39;query-target-filter=wcard(vzFilter.dn,\u0026#34;/subj-[permit]/\u0026#34;)\u0026#39; This is one of the trickier questions.\nfilter(vzFilter) object is where you define what the filter contains filter entries(vzEntry) object is where you define the specific protocols. Multiple entries can be part of the same filter subject filter(vzSubjFFiltAtt) is where you apply the action permit/deny; hence, this is the class we want to query for. Potential Solutions: One of the things that I can try is to be more precise in the vzRsSubjFiltAtt description, and I can directly tell ChatGPT to use this class for retrieving actions. However, this is not a single instance.\nQ43 - Unable to Comprehend Well When Synonymous Words Used For Different Reasons\nGiven the following object descriptions and question:\n### aaaModLR: audit log class * `user`: name of the user who performed the action * `ind`: used to indicate the state of an object. valid values are `creation`, `modification` or `deletion` * `created`: a property indicate when the specific audit log was created. this does not imply whether a configuration is `created`, `modified` or `deleted` **note** to get dates of audit log, use `created`. To get configurations made, use `ind` Question: how to find the total number of configuration changes created between 2024–03–20 and 2024–03–25?\ncorrect answer cmd: moquery -c aaaModLR -x \u0026#39;query-target-filter=and(eq(aaaModLR.ind,\u0026#34;creation\u0026#34;),bw(aaaModLR.created,\u0026#34;2024-03-20T00:00\u0026#34;,\u0026#34;2024-03-25T23:59\u0026#34;))\u0026#39; rsp-subtree-include=count gpt answer cmd: moquery -c aaaModLR -x \u0026#39;query-target-filter=bw(aaaModLR.created,\u0026#34;2024-03-20T00:00\u0026#34;,\u0026#34;2024-03-25T23:59\u0026#34;) rsp-subtree-include=count\u0026#39;` Here is an example output\n# aaa.ModLR id : 4294967791 affected : uni/backupst/snapshots-[uni/fabric/configexp-DailyAutoBackup]/snapshot-run-2024-03-25T17-00-15 cause : transition changeSet : name:run-2024-03-25T17-00-15, retire:no, userdom:all childAction : clientTag : code : E4208927 created : 2024-03-25T17:00:18.868+00:00 descr : Snapshot run-2024-03-25T17-00-15 created dn : subj-[uni/backupst/snapshots-[uni/fabric/configexp-DailyAutoBackup]/snapshot-run-2024-03-25T17-00-15]/mod-4294967791 ind : creation modTs : never rn : mod-4294967791 sessionId : severity : info status : trig : config txId : 221489 user : admin The line: ind : creation implies the actual action taken. In this case, the user created a new object. Other potential values are modified and deleted. The line: created : 2024–03–25T17:00:18.868+00:00 implies when the creation happened. This is somewhat confusing to the model. It couldn\u0026rsquo;t understand the difference between created and creation, and ChatGPT ended up ignoring that field altogether in the example provided above. I also intentionally added a \u0026ldquo;note\u0026rdquo; to help ChatGPT better understand the difference but without luck. Again, Anthropic\u0026rsquo;s Claude Opus 3 wins-I am pretty impressed. Below is the answer on the first try. This also validates that my instruction is OK.\nTo find the total number of configuration changes created between 2024–03–20 and 2024–03–25, use the following query:\nmoquery -c aaaModLR -x \u0026lsquo;query-target-filter=and(eq(aaaModLR.ind,\u0026ldquo;creation\u0026rdquo;),bw(aaaModLR.created,\u0026ldquo;2024–03–20\u0026rdquo;,\u0026ldquo;2024–03–25\u0026rdquo;))\u0026rsquo; rsp-subtree-include=count\nThe Future Of Domain-Specific LLMs Generative AI with transformers is a fast-paced, evolving technology that showed no signs of slowing down. One of the most promising aspects is that it lowers the bar for non-programmers to automate tasks.\nMany domain experts are not exactly expert programmers. However, the need to automate tasks is increasing as data center technologies become more complex and intertwined.\nI view LLM as another programming abstraction layer, similar to Python, as an abstraction layer to C/C++ for specific libraries.\nFor simple or even mildly complex tasks, LLMs are the perfect tools to empower data center engineers and architects to be more efficient, for example:\nDuring troubleshooting, engineers can describe a problem at a high level for LLM, executing commands across different devices to collect information. This cannot be easily automated using Ansible or Python because every situation is unique. However, Ansible/Python can become a tool for LLM to retrieve relative information. (We\u0026rsquo;ll demonstrate this in a future blog)\nWhen performing configuration tasks, LLM can assist in configuration recommendations. This is extremely powerful, for example:\nswitch trunk allowed v \u0026lt;vlan\u0026gt;\nvs. switch trunk allowed v add \u0026lt;vlan\u0026gt;\nmakes a huge difference.\nNow, LLM has advanced to the point where we can describe intentions at the human level instead of code. The trade-off is that we lose some control of the outcome.\nIf you were to hire an assistant to help you in your daily networking tasks, what would you trust/not trust that assistant with?\nConclusions Instruction tuning is one of my favorite approaches to enhance LLMs\u0026rsquo; ability for domain-specific tasks because it is human-friendly and more approachable for non-programmers.\nHowever, the downside is hallucinations, less control, and constant tweaking of the instruction language, which can be frustrating.\nOn the other hand, function calling is the opposite, where the software engineer controls 90% of the outcome but requires more engineering efforts, and not all use cases are covered.\nI will explore multi-agent and multi-modality in future blogs for a more robust user experience; stay tuned!\nI hope you enjoyed this article; please reach out to me on LinkedIn if you have any questions or want to discuss this further !!\nLastly, some data didn\u0026rsquo;t get their spotlight, but they also provided good insights.\nExtra Data For Fun Total Tokens and Cost (estimate) Zero-shot: using gpt-4–1106-preview, this run costs $0.03 with 3465 tokens for 9.53% accuracy.\nFew-shot: using gpt-4–1106-preview, this run costs $0.05 with 4834 tokens for 39.72% accuracy.\nInstruction-tuned: using gpt-4–1106-preview, this run costs $0.13 with 12666 tokens for 77.52% accuracy.\nThe above clearly shows a trade-off between cost and accuracy.\nInvalid Syntax Stats For Tuned Instruction Below is a chart showing the number of invalid syntax for each question. This is a good measure of hallucinations. Technically speaking, if ChatGPT understood the syntax instructions, there would be fewer hallucinations. Imagine ChatGPT making up English phrases that never existed.\nIn my experience, we rarely see syntax errors when coding or grammatical errors when conversing, implying that the model has seen enough data to avoid making such simple mistakes.\nAs shown below, without tuning, zero-shot and few-shot learnings are far from getting even the syntax correct.\n","permalink":"http://zhangineer.net/posts/2024-05-05-supercharge-llm-with-domain-expert-knowledge/","summary":"System Instructions are more potent than you might realize\nI have seen many posts from Network Engineers and Architects dismissing LLM’s ability to perform domain-specific tasks. While it is true that a generic LLM software like ChatGPT does not possess the same level of domain knowledge, it has a high potential to outperform humans if given proper guidance and some teaching.\nIn this post, I will cut through the noise and examine how to “teach” chatGP to answer domain-specific questions like an expert.","title":"Networking and LLM — Supercharge LLM With Domain Expert Knowledge"},{"content":"Using RAG to Enforce ACI Policy Standards\nNetworking management can be complex and depends on accurate information to take necessary actions. Taking the wrong action can be costly.\nPhoto by Susan Q Yin on Unsplash\nThis article is part of a series. Here are the links to the previous articles\nPart I — Introduction Part II — Exploring Basic Interactions Part III — In-Depth Analysis of ChatGPT’s Responses In this article, we’ll first briefly discuss the basics of RAG, the process, and the components that makeup RAG. Then, we’ll observe ChatGPT and review its response in each step.\nRAG (Retrieval Augmented Generation) Large Language Models (LLMs) like ChatGPT have a fundamental limitation: they possess a fixed knowledge cutoff date and don’t continually learn like humans. Moreover, they cannot answer queries about private, unpublished data. While function calls in LLMs can fetch real-time information via REST APIs from other applications, this approach falls short when searching proprietary documents.\nRAG addresses this gap effectively. It retrieves relevant information from a document or a collection of documents, making it particularly useful in contexts where proprietary information is crucial. This article will showcase how RAG can be used to pull configuration guidelines from documents, aiding in auditing configuration changes before deployment. The retrieval process is automatic via function calls triggered by ChatGPT upon detecting a configuration change request.\nRAG-enhanced responses use the information as an added layer of context to the existing instructions.\nThe diagram below illustrates the components and their interactions; note the Pinecone vector database as a critical new element.\nRAG components\nVector Database Vector databases are integral to RAG’s functionality. They store vectors — numerical representations of words (e.g., [0.1, 0.3, 0.123]) — essential in making text documents machine-readable. Common document formats like MS Word, PDF, Markdown, or plain text files must be converted into these vectors.\nWhile direct retrieval from documents is possible, using a vector database is more efficient and cost-effective. Continually converting documents into vectors for each retrieval is unsustainable and expensive.\nThe goal during retrieval is to extract only the most pertinent information in response to a user query, not the entire document.\nFor this demonstration, we utilize Pinecone, a cloud-based vector database, to showcase the power and efficiency of this approach.\nUse Cases Let’s explore several practical use cases where RAG can be applied in networking:\nNetworking Configuration Autocorrect: Before implementing configuration changes, verifying adherence to specific standards is crucial. This could involve ensuring that naming conventions are followed, network interfaces are set up according to a designated template or verifying that a new firewall ACL aligns with the security posture. The goal is to either confirm the user’s compliance with these standards or to provide recommendations when deviations occur.\nDistributed Information Retrieval: Network engineers often need to access guidelines and policy standards quickly for configuration changes. These policies may be scattered across various documents, databases, or different sections within the same document. Utilizing RAG, we can consolidate this search into a single query, retrieving only the most pertinent information to aid the engineer in completing their task efficiently.\nTroubleshooting Steps Retrieval: In cases where network operators receive alerts for network events, immediate access to relevant troubleshooting documentation is vital. RAG can be used to locate and retrieve these documents quickly. Furthermore, troubleshooting steps can be carried out by machines following these documents. This not only expedites the resolution process but also ensures accuracy. (We will explore this scenario in greater depth in future blogs.)\nThis article will focus on demonstrating use case #1 — Networking Configuration Autocorrect in a Cisco ACI environment.\nExample Document Used The documentation below details our ACI naming convention and configuration guidelines.\nWe will specifically showcase configuring a new Bridge Domain and assess how effectively ChatGPT can recommend the correct course of action to a user based on these guidelines.\n# Cisco ACI Configuration Guidelines for LLM This guideline is to help facilitate autonomous agents of LLM This document describes the policy and standards to be followed when configuring the Cisco ACI fabric. All LLM configurations must strictly follow this guideline. This is a living document and will be updated frequently. ## Glossary and Abbreviations * TN = Tenant * AP = Application Profile * EPG = Endpoint Group * BD = Bridge Domain ## Naming Conventions * All new objects that the user wants to create shall be in all caps, no CamelCase or lowercase allowed. * All new objects that the user wants to create shall be concatenated with underscore `_` only, `-`, or `.` shall not be used * When numbers are involved, digit paddings must be used, Bridge Domains uses 4 digits padding, whereas interface numbers uses 2 digit padding. * When registering new Leafs, must follow the following format `LEAF\u0026lt;number\u0026gt;` ## Creating new Bridge Domains * BDs always follow the naming convention of `BD_VLAN\u0026lt;vlan_id\u0026gt;`, where `vlan_id` should be a 4 digit, with 0s as paddings if less than 4 digit * Unicast routing must be enabled for all BDs, there are no layer2 BDs in the environment * All BDs must be associated with the L3Out `OSPF_L3OUT` for advertising the routes out * All BDs must have `ARP flooding enabled` and `L2unknown unicast set to flood` to compensate for silent hosts * All BDs must have GARP detection enabled * All subnets must have `public` and `primary` flags checked ## Creating new EPGs * Before creating new EPGs, ensure that the Tenant, AP already exists * EPGs should always follow the naming convention of `EPG_VLAN\u0026lt;vlan_id\u0026gt;` with paddings of 0s as well * A domain must be associated first, we use `VMM_DOM` for VMWare, and `VMM_PHYS` for static paths * All EPGs must have `preferred group` set as `included` Preparation Before querying the document, a couple of preparatory steps are necessary:\nLoading the Documentation: The document is first uploaded to Pinecone vector databases. We employ a “chunking” technique where a Markdown document is broken down by each section. Depending on the use case, chunking can also be done by sentence or paragraph.\nDefining System Instructions and Function Definitions: To use RAG dynamically, we introduce an additional function call, tailored for scenarios where a network administrator submits a configuration change request.\nFunction Call Definition get_configuration_guideline_function = create_function_config( name=\u0026#34;get_configuration_guideline\u0026#34;, description=\u0026#34;Get guidelines for ACI policy standards,\u0026#34;, properties={ \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;query from the network admin\u0026#34; } }, required=[\u0026#34;query\u0026#34;] ) The actual function to be called def get_configuration_guideline(query): # create an index for query, from the database named \u0026#34;aci-kb\u0026#34; index = create_pinecone_index(\u0026#34;aci-kb\u0026#34;) # query the index, and return the result in plain text for us. context = query_vector_store(index, query) # This ensures ChatGPT does not \u0026#34;forget\u0026#34; other instructions. return f\u0026#34;\u0026#34;\u0026#34; Think step by step when answering user query following the configuration guidelines If no guideline provided for a specific policy, do not proceed and let the user know a policy is missing Step 1. Follow system instruction Step 2. Follow additional instruction: {context} Step 3. Answer the query:\\n \\t{query} \u0026#34;\u0026#34;\u0026#34; Flow Sequence User Prompt Initiation: The user begins by entering a prompt\nRequest Assessment and Doc Retrieval: ChatGPT evaluates if the request is configuration change related. Upon confirmation, it proceeds to fetch the relevant sections from configuration guidelines.\nCompliance Check and Recommendations: ChatGPT evaluates if the user’s proposed configuration complies with the guidelines. Non-compliant configurations will trigger recommendations for correction.\nConfiguration Update and Feedback: The updated configuration is applied to Cisco ACI once the user approves. The results are then reported back to the user.\nAPI Call Sequence Flow\nChatGPT Response Analysis User Request How can I assist you today? =\u0026gt; add vlan5 to tenant demo use vrf vrf_demo, subnet 192.168.1.1/24, subnet should be shared across vrf To summarize the user request — add a new bridge domain with the following settings:\nTenant: demo BD: vlan5 VRF: vrf_demo subnet: 192.168.1.1/24 subnet properties: public and shared No additional details were provided. However, based on our configuration guidelines, the following settings should also be configured:\nEnable Unicast Routing Enable GARP Subnet must have the primary flag Associate any new Bridge Domain with OSPF_L3OUT Adhere to strict naming conventions Relevant Information Retrieved The below response is output from get_configuration_guideline function call and sent to ChatGPT as additional context.\n==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_configuration_guideline\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{\\n \\\u0026#34;query\\\u0026#34;: \\\u0026#34;add vlan5 to tenant demo use vrf vrf_demo, subnet 192.168.1.1/24, subnet should be shared across vrf\\\u0026#34;\\n}\u0026#34; } Think step by step when answering user query following the configuration guidelines If no guideline provided for a specific policy, do not proceed and let the user know a policy is missing Step 1. Follow system instruction Step 2. Follow additional instruction: * Before creating new EPGs, ensure that the Tenant, AP already exists * EPGs should always follow the naming convention of `EPG_VLAN\u0026lt;vlan_id\u0026gt;` with paddings of 0s as well * A domain must be associated first, we use `VMM_DOM` for VMWare, and `VMM_PHYS` for static paths * All EPGs must have `preferred group` set as `included` * BDs always follow the naming convention of `BD_VLAN\u0026lt;vlan_id\u0026gt;`, where `vlan_id` should be a 4 digit, with 0s as paddings if less than 4 digit * Unicast routing must be enabled for all BDs, there are no layer2 BDs in the environment * All BDs must be associated with the L3Out `OSPF_L3OUT` for advertising the routes out * All BDs must have `ARP flooding enabled` and `L2unknown unicast set to flood` to compensate for silent hosts * All BDs must have GARP detection enabled * All subnets must have `public` and `primary` flags checked * TN = Tenant * AP = Application Profile * EPG = Endpoint Group * BD = Bridge Domain Step 3. Answer the query: add vlan5 to tenant demo use vrf vrf_demo, subnet 192.168.1.1/24, subnet should be shared across vrf Observations:\nCore information about Bridge Domain was accurately retrieved.\nAdditional EPG-related information was also retrieved, likely due to the mention of vlan5.\nThe vector search accuracy could be improved, as it fetched some irrelevant sections — such as the glossary section.\nImportant: Since the document was initially split up and stored by section, matching similar text within a section retrieves the entire section.\nWith these guidelines retrieved, let’s examine ChatGPT’s response.\nChatGPT\u0026rsquo;s Recommendation Based on the configuration guidelines, here are the configurations to be made: * Tenant Name: demo * Bridge Domain Name: BD_VLAN0005 * VRF Name: vrf_demo * Unicast Routing: yes * GARP Mode: garp * L2 Unknown Unicast: flood * ARP Flood: yes * L3Outs: OSPF_L3OUT * Subnets: 192.168.1.1/24|yes|public+shared Please confirm if you would like to proceed with these configurations. ==End of response== Highlights:\nChatGPT did not mistakenly capitalize the Tenant name demo nor the VRF name vrf_demo. We\u0026rsquo;ll further discuss later why this was highlighted. The Bridge Domain name was appropriately converted to uppercase with zeros padding the VLAN ID. All additional parameters not specified by the user were adequately added according to the guideline. ChatGPT correctly inferred that the subnet setting should be both public and shared. Lastly, ChatGPT sought user confirmation before executing the changes. Result: The configuration was successfully applied.\nHow can I assist you today? =\u0026gt; yes ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;create_bd\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{\\n \\\u0026#34;tenantName\\\u0026#34;: \\\u0026#34;demo\\\u0026#34;,\\n \\\u0026#34;bdName\\\u0026#34;: \\\u0026#34;BD_VLAN0005\\\u0026#34;,\\n \\\u0026#34;vrfName\\\u0026#34;: \\\u0026#34;vrf_demo\\\u0026#34;,\\n \\\u0026#34;unicastRoute\\\u0026#34;: \\\u0026#34;yes\\\u0026#34;,\\n \\\u0026#34;garp\\\u0026#34;: \\\u0026#34;garp\\\u0026#34;,\\n \\\u0026#34;L2UnknownUnicast\\\u0026#34;: \\\u0026#34;flood\\\u0026#34;,\\n \\\u0026#34;arpFlood\\\u0026#34;: \\\u0026#34;yes\\\u0026#34;,\\n \\\u0026#34;l3outs\\\u0026#34;: \\\u0026#34;OSPF_L3OUT\\\u0026#34;,\\n \\\u0026#34;subnets\\\u0026#34;: \\\u0026#34;192.168.1.1/24|yes|public+shared\\\u0026#34;\\n}\u0026#34; } FUNCTION CALL RESULT: (200, {\u0026#39;totalCount\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;imdata\u0026#39;: []}) The configuration has been successfully applied. The new bridge domain BD_VLAN0005 has been added to the tenant demo. ==End of response== Information Queries and RAG Lastly, for information queries, no configuration guidelines should be retrieved as illustrated below:\nHow can I assist you today? =\u0026gt; what\u0026#39;s my fabric health score ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_fabric_health\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } FUNCTION CALL RESULT: {} I\u0026#39;m sorry, but I didn\u0026#39;t get any results for the fabric health score. ==End of response== How can I assist you today? =\u0026gt; can you get me all the BDs with ur enabled ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_bd\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{\\n \\\u0026#34;unicastRoute\\\u0026#34;: \\\u0026#34;yes\\\u0026#34;\\n}\u0026#34; } FUNCTION CALL RESULT: [{\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.0.177.192\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-mgmt/BD-inb\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-11-04T17:52:40.449+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;inb\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;16386\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;2818048\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;16318374\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;proxy\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;all\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}, {\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.0.39.96\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-common/BD-default\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-11-04T17:52:40.450+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;default\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;32770\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;2654208\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;15826914\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;proxy\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;all\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}, {\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.1.41.144\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-infra/BD-ave-ctrl\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-11-04T17:52:40.450+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;ave-ctrl\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;32771\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;2424832\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;16482194\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;proxy\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;all\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}, {\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.0.0.16\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-infra/BD-default\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-11-04T17:52:25.606+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;default\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;49154\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;16777199\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;16777209\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;proxy\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;all\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}, {\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.0.45.128\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-common/BD-BD_VLAN0005\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-11-29T07:46:21.447+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;BD_VLAN0005\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;any\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;16187318\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;15374\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;proxy\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;:all:\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}, {\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.0.150.16\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-demo/BD-demo_bd\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-12-01T07:12:16.706+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;demo_bd\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;16389\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;3047424\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;16711542\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;15374\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;proxy\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;:all:\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}, {\u0026#39;fvBD\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;OptimizeWanBandwidth\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;annotation\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;arpFlood\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;bcastP\u0026#39;: \u0026#39;225.0.192.48\u0026#39;, \u0026#39;childAction\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;configIssues\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;descr\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;dn\u0026#39;: \u0026#39;uni/tn-demo/BD-BD_VLAN0005\u0026#39;, \u0026#39;enableRogueExceptMac\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epClear\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;epMoveDetectMode\u0026#39;: \u0026#39;garp\u0026#39;, \u0026#39;extMngdBy\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;hostBasedRouting\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteBumTrafficAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;intersiteL2Stretch\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;ipLearning\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;ipv6McastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;lcOwn\u0026#39;: \u0026#39;local\u0026#39;, \u0026#39;limitIpLearnToSubnets\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;llAddr\u0026#39;: \u0026#39;::\u0026#39;, \u0026#39;mac\u0026#39;: \u0026#39;00:22:BD:F8:19:FF\u0026#39;, \u0026#39;mcastARPDrop\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;mcastAllow\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;modTs\u0026#39;: \u0026#39;2023-12-01T09:24:08.731+00:00\u0026#39;, \u0026#39;monPolDn\u0026#39;: \u0026#39;uni/tn-common/monepg-default\u0026#39;, \u0026#39;mtu\u0026#39;: \u0026#39;inherit\u0026#39;, \u0026#39;multiDstPktAct\u0026#39;: \u0026#39;bd-flood\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;BD_VLAN0005\u0026#39;, \u0026#39;nameAlias\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerKey\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ownerTag\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;pcTag\u0026#39;: \u0026#39;any\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;seg\u0026#39;: \u0026#39;15105996\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;regular\u0026#39;, \u0026#39;uid\u0026#39;: \u0026#39;15374\u0026#39;, \u0026#39;unicastRoute\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;unkMacUcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;userdom\u0026#39;: \u0026#39;:all:\u0026#39;, \u0026#39;v6unkMcastAct\u0026#39;: \u0026#39;flood\u0026#39;, \u0026#39;vmac\u0026#39;: \u0026#39;not-applicable\u0026#39;}}}] Here are the Bridge Domains (BDs) with Unicast Routing (UR) enabled: 1. BD Name: inb, Tenant: mgmt, DN: uni/tn-mgmt/BD-inb 2. BD Name: default, Tenant: common, DN: uni/tn-common/BD-default 3. BD Name: ave-ctrl, Tenant: infra, DN: uni/tn-infra/BD-ave-ctrl 4. BD Name: default, Tenant: infra, DN: uni/tn-infra/BD-default 5. BD Name: BD_VLAN0005, Tenant: common, DN: uni/tn-common/BD-BD_VLAN0005 6. BD Name: demo_bd, Tenant: demo, DN: uni/tn-demo/BD-demo_bd 7. BD Name: BD_VLAN0005, Tenant: demo, DN: uni/tn-demo/BD-BD_VLAN0005 Please note that the DN (Distinguished Name) is the unique identifier for each BD in the ACI fabric. Challenges The Main Challenge Despite the smooth appearance of the demonstrated process, one of the most time-consuming challenges was guiding ChatGPT to correctly understand and apply exceptions in the context of configuration guidelines.\nConsider the following statements from our configuration guidelines:\n* All new objects that the user wants to create shall be in all caps, no CamelCase or lowercase allowed. * All new objects that the user wants to create shall be in all caps, no CamelCase or lowercase allowed. e.g. VRF_PROD The only difference between these statements is the addition of e.g. VRF_PROD in the second guideline. This seemingly minor variation led ChatGPT to capitalize both Tenant and VRF names even though they are existing objects, as shown in the following interaction:\nHow can I assist you today? =\u0026gt; add vlan5 to tenant demo use vrf vrf_demo, subnet 192.168.1.1/24, subnet should be shared across vrf ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_configuration_guideline\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{\\n\\\u0026#34;query\\\u0026#34;: \\\u0026#34;add vlan5 to tenant demo use vrf vrf_demo, subnet 192.168.1.1/24, subnet should be shared across vrf\\\u0026#34;\\n}\u0026#34; } Think step by step when answering user query following the configuration guidelines If no guideline provided for a specific policy, do not proceed and let the user know a policy is missing Step 1. Follow system instruction Step 2. Follow additional instruction: \u0026lt;snip\u0026gt; * All new objects that the user wants to create shall be in all caps, no CamelCase or lowercase allowed. e.g. VRF_PROD \u0026lt;snip\u0026gt; Based on the configuration guidelines, here is the configuration to add vlan5 to tenant demo using vrf vrf_demo with subnet 192.168.1.1/24: * Tenant Name: DEMO \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; * Bridge Domain Name: BD_VLAN0005 * VRF Name: VRF_DEMO \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; * Unicast Routing: Yes * GARP: Enabled * L2 Unknown Unicast: Flood * ARP Flooding: Yes * L3Out: OSPF_L3OUT * Subnets: 192.168.1.1/24|yes|public+shared Interestingly and frustratingly, we can guide and reason with ChatGPT to correct its mistake. As shown below:\nMe: Why are the Tenant\u0026rsquo;s name and VRF\u0026rsquo;s name capitalized?\nChatGPT: The configuration guidelines specify that all new objects that the user wants to create should be in all caps. This includes the Tenant name and VRF name. This is a standard naming convention to maintain consistency and avoid confusion. It also helps in easily identifying and differentiating between different objects in the network.\nMe: but Tenant and VRF are existing objects, aren\u0026rsquo;t they? The configuration guideline should only apply to new objects\nChatGPT: You\u0026rsquo;re correct, my apologies for the confusion. The configuration guidelines apply to new objects being created. If the Tenant and VRF are existing objects, we should use their existing names. Let\u0026rsquo;s correct the configuration:\n* Tenant Name: demo * Bridge Domain Name: BD_VLAN0005 * VRF Name: vrf_demo * Unicast Routing: Yes * GARP: Enabled * L2 Unknown Unicast: Flood * ARP Flooding: Yes * L3Out: OSPF_L3OUT * Subnets: 192.168.1.1/24|yes|public+shared Please confirm if you would like to proceed with this configuration. ChatGPT was quick to recognize its mistake. However, various approaches to prevent this misunderstanding initially failed. Why?\nThis issue likely stems from how ChatGPT has been trained and its consequent interpretation of context. During training scenarios where creating new objects might have involved more capitalization examples, it can lead the model to generalize on such a pattern.\nTherefore, in our case, the inclusion of e.g. VRF_PROD might have been perceived as a reinforcement to apply capitalization broadly, leading to capitalizing existing objects incorrectly.\nThis highlights the critical importance of understanding how Generative AI models work and implementing technical safeguards. Such measures are vital when training examples might not adequately address specific contextual subtleties.\nOther Minor Challenges Inconsistencies when Applying Complex Configurations: ChatGPT sometimes struggles with complex configuration requests. For example, when creating a subnet shared across VRFs, ChatGPT occasionally omits the shared flag.\nInconsistencies in Adhering Global Instructions: ChatGPT didn\u0026rsquo;t always follow global instructions as expected when provided with configuration guidelines. It required more explicit steps:\nStep 1. Follow system instruction Step 2. Follow additional instruction: Lack of Document Retrieval Accuracy: There is significant room to improve document retrieval accuracy. Various algorithms can be applied for this purpose, and strategies for chunking and embedding are also crucial. Conclusion In this article we delved into RAG, vector embeddings, and vector databases, illustrating their use in extending LLM capabilities for enforcing ACI policy standards. We demonstrated how RAG can retrieve relevant information from vector databases, align user intentions with policy standards, and offer valuable recommendations. This methodology reduces hallucinations and enhances configuration accuracy while retaining user-friendliness.\nOne Final Thought AI isn\u0026rsquo;t here to replace us but to augment and enhance our capabilities. The synergy between human input and AI is indispensable, especially in crafting solutions catering to a specific knowledge domain or enterprise environment. I encourage all engineers to familiarize themselves with LLM prompt engineering and instruction tuning. This knowledge is vital to effectively guiding these models. I hope you found this series informative and enlightening. Thank you for joining me on this journey!\n","permalink":"http://zhangineer.net/posts/2023-12-10-networking-and-llm-pt4/","summary":"Using RAG to Enforce ACI Policy Standards\nNetworking management can be complex and depends on accurate information to take necessary actions. Taking the wrong action can be costly.\nPhoto by Susan Q Yin on Unsplash\nThis article is part of a series. Here are the links to the previous articles\nPart I — Introduction Part II — Exploring Basic Interactions Part III — In-Depth Analysis of ChatGPT’s Responses In this article, we’ll first briefly discuss the basics of RAG, the process, and the components that makeup RAG.","title":"Networking and LLM in the Age of AI — Pt. IV: Knowledge Retrieval using RAG"},{"content":"Analyze LLM responses and understand hallucinations.\nEfficient Network Operation is about getting precise information without additional \u0026ldquo;digging in.\u0026rdquo;\nThis article is a continuation of a series following parts I and II. We will begin by analyzing several complex conversations and conclude with examples illustrating hallucinations.\nRecap The previous articles covered the basics of instructions, prompts, context, function calls, and how all these components integrate.\nWe also reviewed the responses to a fabric health query. In this article, we will delve deeper into more complex scenarios, thoroughly examining the answers provided by ChatGPT, including:\nRequesting ChatGPT to retrieve information via API calls. Instructing ChatGPT to execute changes through API calls. Analyzing and understanding hallucinations. As outlined in the previous article, here is the global instruction:\n\u0026#34;\u0026#34;\u0026#34; You are a co-pilot to the network engineers. All tasks are executed via function calls Only use the functions you have been provided with. Don\u0026#39;t make assumptions about what values to plug into functions. Always ask for clarification if a user request is ambiguous when you encounter an error during a function call, pass back the exact error message, and do not interpret it \u0026#34;\u0026#34;\u0026#34; We instruct ChatGPT to utilize function calls exclusively using provided functions. Refrain from assuming input or function argument values. Errors should be relayed directly to the user without interpretation, as interpreting errors could lead to inaccurate assumptions or hallucinations by ChatGPT. Asking chatGPT to retrieve information Q: Can you get me a list of BDs with UR enabled?\nHow can I assist you today? =\u0026gt; Can you get me a list of BDs with UR enabled? Function Call Definition get_bd_function = create_function_config( name=\u0026#34;get_bd\u0026#34;, description=\u0026#34;Get information about bridge domains (BD)\u0026#34;, properties={ \u0026#34;unicastRoute\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;unicast routing(UR) settings\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;yes\u0026#34;, \u0026#34;no\u0026#34;] }, \u0026#34;unkMacUcastAct\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;L2 Unknown unicast setting\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;flood\u0026#34;, \u0026#34;proxy\u0026#34;] }, \u0026#34;operator\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;operators are used to filter and concatenate different properties\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;wcard\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;or\u0026#34;, \u0026#34;bw\u0026#34;, \u0026#34;lt\u0026#34;, \u0026#34;gt\u0026#34;] } }, required=[] ) Response from chatGPT Below is a debug message showing ChatGPT correctly interpreted the user intention by returning the correct function name with the expected arguments.\nMaking function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_bd\u0026#34;, # correct function name returned by ChatGPT \u0026#34;arguments\u0026#34;: \u0026#34;{\\n \\\u0026#34;unicastRoute\\\u0026#34;: \\\u0026#34;yes\\\u0026#34;\\n}\u0026#34; # correct argument interpreted by ChatGPT } unicastRoute is a specific ACI class, and it was provided as part of the function definition. ACI API will only accept yes/no as valid values. ChatGPT was able to understand UR as abbreviated in the argument definition \u0026quot;description\u0026quot;: \u0026quot;unicast routing (UR) settings. After making the API call to ACI, we receive the following JSON dictionaries, which we\u0026rsquo;ll pass back to ChatGPT for data extraction: { \u0026#34;fvBD\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;OptimizeWanBandwidth\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;annotation\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;arpFlood\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;bcastP\u0026#34;: \u0026#34;225.1.17.144\u0026#34;, \u0026#34;childAction\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;configIssues\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;descr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dn\u0026#34;: \u0026#34;uni/tn-mgmt/BD-inb\u0026#34;, \u0026#34;enableRogueExceptMac\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;epClear\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;epMoveDetectMode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;extMngdBy\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;hostBasedRouting\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;intersiteBumTrafficAllow\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;intersiteL2Stretch\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;ipLearning\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;ipv6McastAllow\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;lcOwn\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;limitIpLearnToSubnets\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;llAddr\u0026#34;: \u0026#34;::\u0026#34;, \u0026#34;mac\u0026#34;: \u0026#34;00:22:BD:F8:19:FF\u0026#34;, \u0026#34;mcastARPDrop\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;mcastAllow\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;modTs\u0026#34;: \u0026#34;2023-09-09T02:09:23.883+00:00\u0026#34;, \u0026#34;monPolDn\u0026#34;: \u0026#34;uni/tn-common/monepg-default\u0026#34;, \u0026#34;mtu\u0026#34;: \u0026#34;inherit\u0026#34;, \u0026#34;multiDstPktAct\u0026#34;: \u0026#34;bd-flood\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;inb\u0026#34;, \u0026#34;nameAlias\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ownerKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ownerTag\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pcTag\u0026#34;: \u0026#34;16386\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;2621440\u0026#34;, \u0026#34;seg\u0026#34;: \u0026#34;16383902\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;regular\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;unicastRoute\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;unkMacUcastAct\u0026#34;: \u0026#34;proxy\u0026#34;, \u0026#34;unkMcastAct\u0026#34;: \u0026#34;flood\u0026#34;, \u0026#34;userdom\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;v6unkMcastAct\u0026#34;: \u0026#34;flood\u0026#34;, \u0026#34;vmac\u0026#34;: \u0026#34;not-applicable\u0026#34; } } }, { \u0026#34;fvBD\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;OptimizeWanBandwidth\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;annotation\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;arpFlood\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;bcastP\u0026#34;: \u0026#34;225.0.7.80\u0026#34;, \u0026#34;childAction\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;configIssues\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;descr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dn\u0026#34;: \u0026#34;uni/tn-common/BD-default\u0026#34;, \u0026#34;enableRogueExceptMac\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;epClear\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;epMoveDetectMode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;extMngdBy\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;hostBasedRouting\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;intersiteBumTrafficAllow\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;intersiteL2Stretch\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;ipLearning\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;ipv6McastAllow\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;lcOwn\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;limitIpLearnToSubnets\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;llAddr\u0026#34;: \u0026#34;::\u0026#34;, \u0026#34;mac\u0026#34;: \u0026#34;00:22:BD:F8:19:FF\u0026#34;, \u0026#34;mcastARPDrop\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;mcastAllow\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;modTs\u0026#34;: \u0026#34;2023-09-09T02:09:24.610+00:00\u0026#34;, \u0026#34;monPolDn\u0026#34;: \u0026#34;uni/tn-common/monepg-default\u0026#34;, \u0026#34;mtu\u0026#34;: \u0026#34;inherit\u0026#34;, \u0026#34;multiDstPktAct\u0026#34;: \u0026#34;bd-flood\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;nameAlias\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ownerKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ownerTag\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pcTag\u0026#34;: \u0026#34;49154\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;3014657\u0026#34;, \u0026#34;seg\u0026#34;: \u0026#34;16318374\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;regular\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;unicastRoute\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;unkMacUcastAct\u0026#34;: \u0026#34;proxy\u0026#34;, \u0026#34;unkMcastAct\u0026#34;: \u0026#34;flood\u0026#34;, \u0026#34;userdom\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;v6unkMcastAct\u0026#34;: \u0026#34;flood\u0026#34;, \u0026#34;vmac\u0026#34;: \u0026#34;not-applicable\u0026#34; } } }, \u0026lt;SNIP\u0026gt; Below is the final response from ChatGPT (displayed to the user)\nHere is a list of Bridge Domains (BDs) with Unicast Routing (UR) enabled: 1. BD Name: inb, Tenant: mgmt 2. BD Name: default, Tenant: common 3. BD Name: ave-ctrl, Tenant: infra 4. BD Name: default, Tenant: infra 5. BD Name: VLAN5_BD, Tenant: CustomerA 6. BD Name: VLAN500_BD, Tenant: CustomerA 7. BD Name: VLAN100_BD, Tenant: CustomerA 8. BD Name: VLAN5_BD, Tenant: common 9. BD Name: vlan5, Tenant: common 10. BD Name: VLAN101_BD, Tenant: CustomerA Please note that the tenant name indicates the specific network segment where the BD is located. ==End of response== A few interesting observations:\nWe did not specify an expected output format, resulting in ChatGPT \u0026ldquo;selecting\u0026rdquo; one based on its training data. ChatGPT accurately extracted Tenant names from the Distinguished Name (DN), as seen in examples like \u0026ldquo;dn\u0026rdquo;: \u0026ldquo;uni/tn-mgmt/BD-inb\u0026rdquo;. However, ChatGPT inaccurately claimed that \u0026ldquo;the tenant name indicates the specific network segment,\u0026rdquo; revealing a gap in its domain knowledge.\u0026quot; Now, let\u0026rsquo;s try asking ChatGPT to make a configuration update\nAsking ChatGPT to make a change Q: can you add a new BD named VLAN_NEW to tenant customera\nHow can I assist you today? =\u0026gt; can you add a new BD named VLAN_NEW to tenant customera I intentionally included two mistakes in the prompt:\nNo VRF name was provided Typo in the Tenant name customera Function Call Definition build_bd_function = create_function_config( name=\u0026#34;create_bd\u0026#34;, description=\u0026#34;Create a bridge domain using inputs from user, \u0026#34; \u0026#34;make sure to validate that the given Tenant and VRF exist first\u0026#34;, properties={ \u0026#34;tenantName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;name of the Tenant to deploy to\u0026#34; }, \u0026#34;bdName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;name of the bridge domain\u0026#34; }, \u0026#34;vrfName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;name of the VRF, required from user\u0026#34;, }, }, required=[\u0026#34;tenantName\u0026#34;, \u0026#34;bdName\u0026#34;, \u0026#34;vrfName\u0026#34;] ) Since there were two mistakes, it took a bit of back and forth between ChatGPT and me.\nFirst Response ==Response== Sure, I can help with that. However, I need the name of the VRF to proceed. Could you please provide the VRF name? ==End of response== ChatGPT detected mistake#1 - the absence of a VRF name, which will lead ACI to fall back to default, which is often undesired. ChatGPT understood this requirement because of several instructions were put in place to ensure the expected behavior:\nIn the global instruction In the function description In the argument description In the required enumeration (Ideally, this should have sufficed, but it didn\u0026rsquo;t during my initial tests, hence the additional instructions ) Second Response We provided ChatGPT prod VRF name, and it successfully executed the function call but encountered an error. The error is then relayed back to the user as instructed.\nHow can I assist you today? =\u0026gt; use prod # This is a reply to the question from ChatGPT ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;create_bd\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{\\n \\\u0026#34;tenantName\\\u0026#34;: \\\u0026#34;customera\\\u0026#34;,\\n \\\u0026#34;bdName\\\u0026#34;: \\\u0026#34;VLAN_NEW\\\u0026#34;,\\n \\\u0026#34;vrfName\\\u0026#34;: \\\u0026#34;prod\\\u0026#34;\\n}\u0026#34; } FUNCTION CALL RESULT: {\u0026#39;totalCount\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;imdata\u0026#39;: [{\u0026#39;error\u0026#39;: {\u0026#39;attributes\u0026#39;: {\u0026#39;code\u0026#39;: \u0026#39;102\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;configured object ((Dn0)) not found Dn0=uni/tn-customera/BD-VLAN_NEW, \u0026#39;}}}]} I\u0026#39;m sorry, but there was an error while creating the bridge domain. The error message is: \u0026#34;configured object ((Dn0)) not found Dn0=uni/tn-customera/BD-VLAN_NEW\u0026#34;. It seems like the tenant or the VRF might not exist. Would you like to check the existing tenants and VRFs? ==End of response== ChatGPT accurately identified the function name and all required arguments. Since ACI utilizes DNs for each object, the existence of a parent object is a prerequisite in this case. This is why we received the error: object ((Dn0)) not found Dn0=uni/tn-customera/BD-VLAN_NEW implying that the Tenant customera does not exist We intentionally directed ChatGPT not to interpret errors. Instead, as outlined in ructions, it is instructed to relay all errors to users for further analysis. ChatGPT offered a follow-up suggestion: Would you like to check the existing tenants and VRFs? However, that was not the root cause. So, instead, I asked what the available Tenants are (as shown below). This example underscores the importance of human intervention, as there can be various options with different implications. ChatGPT may not fully grasp the user\u0026rsquo;s intent without additional guidance. Third Response We prompted ChatGPT to identify the available Tenants to reassure the Tenant names, and it executed the correct function call, subsequently returning the results.\nHow can I assist you today? =\u0026gt; what are available tenants ? ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_tenant\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } Here are the available tenants: 1. Tenant Name: infra 2. Tenant Name: common 3. Tenant Name: mgmt 4. Tenant Name: CustomerA Please note that the tenant names are case sensitive. It seems like there was a typo in the tenant name you provided earlier. The correct tenant name should be \u0026#34;CustomerA\u0026#34; instead of \u0026#34;customera\u0026#34;. ==End of response== Again, ChatGPT precisely identified the necessary function call to execute - get_tenant ChatGPT successfully read and interpreted the results from the function call (recall that ACI API will only return JSON) Notably, ChatGPT caught the typo and suggested a correction. Final Response With all the necessary information, we can let ChatGPT resolve the problem automatically by simply instructing it to act on our behalf. We also requested the updated BD list after receiving a success message.\nHow can I assist you today? =\u0026gt; okay, fix it for me ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;create_bd\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{\\n \\\u0026#34;tenantName\\\u0026#34;: \\\u0026#34;CustomerA\\\u0026#34;,\\n \\\u0026#34;bdName\\\u0026#34;: \\\u0026#34;VLAN_NEW\\\u0026#34;,\\n \\\u0026#34;vrfName\\\u0026#34;: \\\u0026#34;prod\\\u0026#34;\\n}\u0026#34; } FUNCTION CALL RESULT: {\u0026#39;totalCount\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;imdata\u0026#39;: []} The bridge domain \u0026#34;VLAN_NEW\u0026#34; has been successfully created in the tenant \u0026#34;CustomerA\u0026#34; with the VRF \u0026#34;prod\u0026#34;. ==End of response== How can I assist you today? =\u0026gt; show me the new list of BDs ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_bd\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } Here is the updated list of Bridge Domains (BDs): 1. BD Name: inb, Tenant: mgmt 2. BD Name: default, Tenant: common 3. BD Name: ave-ctrl, Tenant: infra 4. BD Name: default, Tenant: infra 5. BD Name: VLAN5_BD, Tenant: CustomerA 6. BD Name: VLAN500_BD, Tenant: CustomerA 7. BD Name: VLAN100_BD, Tenant: CustomerA 8. BD Name: VLAN5_BD, Tenant: common 9. BD Name: vlan5, Tenant: common 10. BD Name: VLAN101_BD, Tenant: CustomerA 11. BD Name: VLAN_NEW, Tenant: CustomerA The new BD \u0026#34;VLAN_NEW\u0026#34; has been successfully added to the tenant \u0026#34;CustomerA\u0026#34;. ==End of response== Asking chatGPT to retrieve BD count Q: How many BDs are there?\nHow can I assist you today? =\u0026gt; how many BDs are there ? ==Response== There are 11 Bridge Domains (BDs) in total. ==End of response== ChatGPT directly retrieved the information from previous conversations (note the absence of Making function call debug message). If I exit the program and begin a new conversation, it\u0026rsquo;s apparent that ChatGPT needs to query for all Bridge Domains (BDs) again to retrieve the answer\nchattynetworks git:(main) ✗ python chattynetworks/aci/chat.py Hi, I\u0026#39;m an ACI GPT agent, I can provide information for your ACI fabric How can I assist you today? =\u0026gt; how many BDs are there ? ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_bd\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } There are 11 Bridge Domains (BDs). ==End of response== The main difference here is that generating a response from context is much faster but also cheaper $\nHallucinations or Imaginations? Hallucinations in LLMs occur when the model generates text that is erroneous, nonsensical, or disconnected from reality. Interestingly, hallucinations can also spur AI creativity and sometimes better grasp human intentions, a topic worthy of separate discussion.\nLet\u0026rsquo;s examine the following examples to understand how hallucinations might manifest in networking operations.\nFirst Example Here is a snippet of my interaction with ChatGPT regarding fabric health scores:\nQ: what\u0026rsquo;s my fabric healthscore ?\nA: The health score of your fabric is 81.\nQ: how is my fabric doing?\nA: The overall health of your fabric is currently at 81%.\nQ: Is my fabric good ? A: Yes, your fabric is in good condition. The health score is 81, which indicates a healthy state.\nQ: can you raise the threshold to 90 to be considered good ?\nA: I\u0026rsquo;m sorry, but as an AI, I don\u0026rsquo;t have the capability to change the threshold for what is considered a good health score. This is typically a decision made by network administrators based on their specific requirements and standards.\nWhile identical in intent, the first two questions received slightly different responses from ChatGPT (an inconsistency in format, but not inherently negative). The third question, a straightforward yes/no query, received not just an answer but an explanation from ChatGPT, demonstrating some reasoning capability. However, I had not provided ChatGPT with any criteria for \u0026lsquo;good\u0026rsquo; or \u0026lsquo;bad.\u0026rsquo; This is an area where custom instructions could refine the response, similar to thresholds used in other networking solutions. The fourth question tested ChatGPT\u0026rsquo;s response to on-the-fly threshold adjustments. Its response was somewhat lacking, considering I am the administrator and that it should have followed my directives. Second Example Background: I had just set up a fresh ACI simulator instance with no devices registered, so no healthscore was available.\nHow can I assist you today? =\u0026gt; how\u0026#39;s my fabric ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_fabric_health\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } # ACI Returned empty results FUNCTION CALL RESULT: {} The fabric health is in good condition. ==End of response== This is a clear case of hallucination. Ideally, when ACI returns an empty result, ChatGPT should report it as is. Instead, it incorrectly informed me that the fabric was in good condition, which is misleading.\nI managed to rectify the hallucination issue by introducing a new directive:\nAddition to the global instruction: If no results are returned after a function call, let the user know; with this additional instruction in place, ChatGPT provided the anticipated response:\nHow can I assist you today? =\u0026gt; How\u0026#39;s my fabric ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_fabric_health\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } FUNCTION CALL RESULT: {} I\u0026#39;m sorry, but there were no results returned after the function call. ==End of response== This solution, while straightforward, underscores how prone LLMs are to hallucinations, even in situations that might seem obvious to humans.\nObservations ChatGPT might assume values when not provided by the user, a side effect of training on generic internet data. Instead of grasping the fundamental concept, ChatGPT often applies these trained examples to answer user queries. Therefore, additional instructions are necessary to minimize hallucinations. With adequate context and instructions, ChatGPT can assist in correcting configuration mistakes. We\u0026rsquo;ll further explore this in the next article. When ChatGPT is used for data parsing, the output format can vary, which is often undesired for networking operations. Hallucinations present a significant challenge, but there are ways to minimize them. Conclusion In this article, we delved into ChatGPT\u0026rsquo;s responses to a variety of networking requests, assessing its reasoning capabilities and basic troubleshooting skills in the typo example.\nWe also observed an instance of hallucination and implemented a straightforward solution. In our next article, we will explore RAG (Retrieval Augmented Generation) and examine how it can be utilized to uphold configuration standards — Networking and LLM in the Age of AI - Pt IV: Knowledge Retrieval using RAG\n","permalink":"http://zhangineer.net/posts/2023-11-22-networking-and-llm-pt3/","summary":"Analyze LLM responses and understand hallucinations.\nEfficient Network Operation is about getting precise information without additional \u0026ldquo;digging in.\u0026rdquo;\nThis article is a continuation of a series following parts I and II. We will begin by analyzing several complex conversations and conclude with examples illustrating hallucinations.\nRecap The previous articles covered the basics of instructions, prompts, context, function calls, and how all these components integrate.\nWe also reviewed the responses to a fabric health query.","title":"Networking and LLM in the Age of AI — Pt. III: In-Depth Analysis of ChatGPT’s Responses"},{"content":"Instructions, Context, Function Calling and Prompts\nThe most crucial information we must provide to any LLM chat model are the context, detailed instructions, and precise prompts.\nThis article is part of a series — You can find Part I here\nInstructions Instructions play a crucial role in shaping an LLM into a valuable assistant. Their purpose is to set clear expectations and guide narratives and context, thereby reducing inaccuracies and ensuring more precise responses.\nCreating practical instructions often involves trial and error and is an iterative process. This is akin to conveying domain expert knowledge to others who aren\u0026rsquo;t familiar with the same domain. Experts familiar with their field might overlook mentioning basic facts or best practices that have become second nature to them.\nWhen it comes to network management, we should establish some fundamental expectations for the LLM:\nInsist on factual responses, avoiding any fabricated or imaginary configurations. Require precise API calls for acquiring specific information or implementing the correct configurations. Avoid making assumptions about input parameters when making API calls. If a prompt is ambiguous, the model should always seek clarification from the user. For instance, we should not assume the use of default values when deploying ACI policies. Adhere strictly to user-defined output formats. Here\u0026rsquo;s an illustrative example of global instructions:\n\u0026#34;\u0026#34;\u0026#34; You are a co-pilot to the network engineers. All tasks are executed via function calls Only use the functions you have been provided with. Don\u0026#39;t make assumptions about what values to plug into functions. Always ask for clarification if a user request is ambiguous when you encounter an error during a function call, pass back the exact error message, and do not interpret it \u0026#34;\u0026#34;\u0026#34; It sets the context for networking administration and specifies the exclusive use of provided function calls. It also instructs ChatGPT not to interpret any error messages, leaving the diagnosis to the network admin. We can also define more granular instructions at the function level (more on this later). This seemingly small set of instructions was created via trial and error over several iterations.\nContext Context is similar to memory for LLM. An LLM has to be mindful of the conversation\u0026rsquo;s context to respond appropriately. Initial contexts are defined as part of the global instructions as shown above.\nAs we engage in a dialogue with ChatGPT, each new piece of information enriches the context. The entirety of the conversation history is repeatedly passed to ChatGPT as the conversation continues, enabling it to generate informed and relevant responses based on this accumulated context.\nWith that said, it\u0026rsquo;s important to note that the context in LLMs is confined to a single conversation and is restricted by the size of its memory, often referred to as the \u0026lsquo;Context Window. This implies that the volume of text an LLM can process at a time is limited. Therefore, \u0026ldquo;reading a book\u0026rdquo; is a challenging task for most LLMs. Don\u0026rsquo;t try sending \u0026ldquo;TCP/IP Volume 1 and 2\u0026rdquo; to ChatGPT and expect some in-depth Q\u0026amp;A sessions.\nFunction Calling While our usual interactions with ChatGPT are conversational, yielding responses in human-readable plain text, we can also use APIs to request that ChatGPT provides a specific function with arguments. This process involves two main components:\nA pre-defined data structure For instance,\nget_fabric_health_function = create_function_config( name=\u0026#34;get_fabric_health\u0026#34;, description=\u0026#34;Get the latest fabric health, provide user min, max and average for the past 5 minutes\u0026#34;, properties={}, required=[] ) name: The name of the function to be called.\ndescription: This serves as an instruction. For instance, in the above example, we specify that the function should get the minimum, maximum, and average values for the past 5 minutes. ChatGPT may default to providing a single value without this explicit instruction.\nproperties: Here, we detail the specifics of the arguments. This includes providing a function description akin to an instruction but at the argument level. Additionally, we can define an enumeration parameter - a list of acceptable values for an argument. (This will be discussed in more detail in the following article.)\nrequired: This field informs ChatGPT which argument(s) are essential. If a user fails to provide sufficient information, ChatGPT may hallucinate from training data.\nNote: ChatGPT utilizes a dictionary structure to define functions. The code mentioned above is designed for abstraction purposes, which accounts for the slight differences in formatting.\nInclude defined functions in the API call res = openai.ChatCompletion.create( model=self.model, messages=self.messages, functions=self.functions, function_call=self.function_call, temperature=0 ) In the process of invoking the ChatCompletion Python API, we specifically incorporate two fields in addition to the common ones: functions`` and function_call``\nThe functions field is a list of function definitions, as previously defined. In our demonstrations, we will include all the specified functions.\nThe function_call field enables us to force the model to use a specific function. By default, this value is set to auto\ntemperature=0 field is not particular to the function call. Setting to 0 helps control hallucination\nYou can find a more detailed example with explanations on OpenAI\u0026rsquo;s Github page - How_to_call_functions_with_chat_models\nPrompts Prompts are the means through which we frame our intentions. In interactions with an LLM model, it is crucial to articulate our intentions clearly and include all relevant information within the prompt.\nEmphasizing simplicity and precision, and with a well-structured context, prompts in this scenario are analogous to CLI commands expressed in human language (Human Language Interface).\nWhile numerous strategies exist for effective prompt engineering, we aim to engage in straightforward English dialogue without relying on advanced prompt engineering yet still execute precise API calls to the APIC.\nConsequently, a basic understanding of networking is necessary to provide ChatGPT with the required parameters during the prompting process\nBelow are some example prompts. Note that here, we used ACI-specific terminology such as \u0026ldquo;fabric,\u0026rdquo; \u0026ldquo;UR (unicast routing),\u0026rdquo; and \u0026ldquo;BD (Bridge Domain)\u0026rdquo; to assess ChatGPT\u0026rsquo;s awareness of context.\n# This question intends to get the fabric health score - How is my fabric doing? # The intention is to get a list of routed BDs, including the default ones. # Excluding default BDs requires further instruction tuning, though - Can you get me a list of BDs with UR enabled? # We\u0026#39;ll further analyze this one in the following article # Can you spot any potential issues in this prompt, though? - Can you add a new BD named VLAN5_BD to Tenant customera? # A simple question to count BDs. # We\u0026#39;ll further analyze ChatGPT\u0026#39;s response in the following article - How many BDs are there? Bring Everything Together Now that we\u0026rsquo;ve covered all the fundamentals, let\u0026rsquo;s see how to integrate these elements sequentially to create a streamlined process.\nOnce we receive a prompt from the user, the first step involves sending the following information to the ChatGPT API.\nGlobal instructions List of functions User prompts This results in the API returning the name of the function we should call and the necessary arguments. We then use this information to execute the appropriate API call to ACI, which yields a JSON response.\nAt this juncture, we have two options:\nWe can send the JSON response back to ChatGPT for parsing, as illustrated above. We\u0026rsquo;ll use this approach for all future demonstrations.\nAlternatively, we can parse the JSON using another function. This approach is less token-intensive but requires more significant software engineering effort.\nFinally, we present the output to the user.\nA Simple Demonstration Now that we understand the entire process flow let\u0026rsquo;s walk through the first query as a simple demonstration. (we\u0026rsquo;ll go into depth in the next article)\nQ: How is my fabric doing?\nRecall that the intention is to simply get the health score (as defined in the function definition).\nHow can I assist you today? =\u0026gt; how\u0026#39;s my fabric doing Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_fabric_health\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } In this instance, specifying the entire \u0026ldquo;Cisco ACI Fabric\u0026rdquo; context wasn\u0026rsquo;t necessary.\nThe function get_fabric_health is correctly returned from ChatGPT with no arguments.\nWe received the below output after sending the above API call to ACI.\n{ \u0026#34;fabricOverallHealthHist5min\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;childAction\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cnt\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;dn\u0026#34;: \u0026#34;topology/HDfabricOverallHealth5min-0\u0026#34;, \u0026#34;healthAvg\u0026#34;: \u0026#34;81\u0026#34;, \u0026#34;healthMax\u0026#34;: \u0026#34;81\u0026#34;, \u0026#34;healthMin\u0026#34;: \u0026#34;81\u0026#34;, \u0026#34;healthSpct\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;healthThr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;healthTr\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;lastCollOffset\u0026#34;: \u0026#34;300\u0026#34;, \u0026#34;repIntvEnd\u0026#34;: \u0026#34;2023-10-17T19:43:56.439+00:00\u0026#34;, \u0026#34;repIntvStart\u0026#34;: \u0026#34;2023-10-17T19:38:55.934+00:00\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;\u0026#34; } } } The JSON output is subsequently sent to ChatGPT for additional data extraction. Following this, ChatGPT provided a response that precisely captured the requested average, minimum, and maximum values despite them being identical\nThe fabric health for the past 5 minutes has been consistent with an average, minimum, and maximum health score of 81. Variations in Prompts Let\u0026rsquo;s examine how ChatGPT responds to slight variations in phrasing the exact prompt.\nExample Prompt: what's my health score? and give me the hs\nHow can I assist you today? =\u0026gt; what\u0026#39;s my health score ? ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_fabric_health\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } Your health score for the past 5 minutes is as follows: - Minimum: 84 - Maximum: 84 - Average: 84 ==End of response== How can I assist you today? =\u0026gt; give me the hs ==Response== Making function call.... { \u0026#34;name\u0026#34;: \u0026#34;get_fabric_health\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{}\u0026#34; } Your health score for the past 5 minutes is as follows: - Minimum: 84 - Maximum: 84 - Average: 84 ==End of response== In both cases, the response outputs differed from the previous instance. This is a common scenario where asking ChatGPT the same question multiple times can result in slightly different outputs, though they convey the same meaning. In this context, the variation isn\u0026rsquo;t a significant issue. With some additional fine-tuning of the instructions, we can address this.\nRemarkably, ChatGPT correctly interpreted hs as health score. A cautionary note: only four functions were provided in this example, which probably helped control hallucinations.\nConclusion ChatGPT demonstrates proficiency in executing API actions when provided with the correct context, clear guidance, and precise function definitions.\nHowever, achieving output consistency comparable to tools like Ansible requires further refinement of instructions and consideration of user experience.\nIn the following article, we\u0026rsquo;ll analyze ChatGPT\u0026rsquo;s responses to the remaining questions in depth, examining its capability to handle more complex scenarios.\nSee you in the next one! Networking and LLM in the Age of AI - Pt III: In-Depth Analysis of ChatGPT\u0026rsquo;s Responses\n","permalink":"http://zhangineer.net/posts/2023-10-29-networking-and-llm-pt2/","summary":"Instructions, Context, Function Calling and Prompts\nThe most crucial information we must provide to any LLM chat model are the context, detailed instructions, and precise prompts.\nThis article is part of a series — You can find Part I here\nInstructions Instructions play a crucial role in shaping an LLM into a valuable assistant. Their purpose is to set clear expectations and guide narratives and context, thereby reducing inaccuracies and ensuring more precise responses.","title":"Networking and LLM in the Age of AI — Pt. II: Exploring Basic Interactions"},{"content":"15 years of experience in the networking field, specializing in Software-Defined Networking (SDN), I have recently delved into the world of AI/ML. My focus has been on researching the applications of Large Language Models (LLMs) in networking, exploring how these advanced technologies can supercharge networking and user experiences.\nExperiences Most recent first\n2 years working in a startup building a Networking AI/ML product 4 years as solutions architect / consultant / pre-sale in networking, specifically Cisco ACI and DataCenter 5 years as a network engineer in Enterprise covering a wide range of technologies - DC/Campus Networking, CDN, Automation 5 years as a tier-1 tech support engineer in an ISP setting White Papers Published Segmenting Complex Environments Using Cisco ACI Demystifying ACI Application Centric \u0026ldquo;Mode\u0026rdquo; Through the Lens of an Engineer Cisco ACI: Design to Automate Career Certifications and Awards Patent: US11606265B2 - Network control in artificial intelligence-defined networking Awarded by WWT as Engineer of the Month/Quarter/Year in 2021 Cisco Certified Network Associate Cisco Certified DevNet Associate Cisco Certified DevNet Professional Cisco Certified DevNet Specialist - Core Cisco Certified DevNet Specialist - Data Center Automation and Programmability Coursera - Generative AI with LLM Coursera - Generative AI for everyone Coursera - Machine Learning Coursera - AI For Everyone My Thoughts On AI My primary goal is to harness the power of LLMs to facilitate the integration of AI/ML into data center designs, effectively bridging the gap between high-level business requirements and network functionalities. This approach is rooted in the philosophy of true intent-based networking, which prioritizes understanding and fulfilling business and application needs, rather than focusing solely on the network infrastructure.\nI believe AI is here to augment, not to replace network engineers. It’s akin to the calculator\u0026rsquo;s role in mathematics: a powerful tool that expands capabilities without diminishing the importance of human expertise. The calculator didn’t replace mathematicians; instead, it made math more accessible and accelerated our learning.\nSimilarly, while the core principles of networking remain crucial, our approach evolves. Engineers need a solid grasp of these fundamentals to discern when an LLM might \u0026lsquo;hallucinate\u0026rsquo;. The shift we’re witnessing moves us away from rote memorization of CLI commands towards a focus on design and business alignment. Our goal is to provide nuanced, business-specific directives to LLMs, enhancing efficiency and customization.\nEnvision a future where networking operations are driven more by human language interfaces than traditional CLI/GUI. This paradigm shift promises a more intuitive, human-centric approach to networking technology\n\u0026ndash; written by me, revised by chatGPT ( of course )\n","permalink":"http://zhangineer.net/aboutme/","summary":"15 years of experience in the networking field, specializing in Software-Defined Networking (SDN), I have recently delved into the world of AI/ML. My focus has been on researching the applications of Large Language Models (LLMs) in networking, exploring how these advanced technologies can supercharge networking and user experiences.\nExperiences Most recent first\n2 years working in a startup building a Networking AI/ML product 4 years as solutions architect / consultant / pre-sale in networking, specifically Cisco ACI and DataCenter 5 years as a network engineer in Enterprise covering a wide range of technologies - DC/Campus Networking, CDN, Automation 5 years as a tier-1 tech support engineer in an ISP setting White Papers Published Segmenting Complex Environments Using Cisco ACI Demystifying ACI Application Centric \u0026ldquo;Mode\u0026rdquo; Through the Lens of an Engineer Cisco ACI: Design to Automate Career Certifications and Awards Patent: US11606265B2 - Network control in artificial intelligence-defined networking Awarded by WWT as Engineer of the Month/Quarter/Year in 2021 Cisco Certified Network Associate Cisco Certified DevNet Associate Cisco Certified DevNet Professional Cisco Certified DevNet Specialist - Core Cisco Certified DevNet Specialist - Data Center Automation and Programmability Coursera - Generative AI with LLM Coursera - Generative AI for everyone Coursera - Machine Learning Coursera - AI For Everyone My Thoughts On AI My primary goal is to harness the power of LLMs to facilitate the integration of AI/ML into data center designs, effectively bridging the gap between high-level business requirements and network functionalities.","title":"About Me"},{"content":"A series to explore how to leverage LLM for networking tasks\nThe rise of chatGPT and large language models (LLM) has opened up the possibility of transforming various domains. However, networking remains largely unexplored.\nIn this series, we\u0026rsquo;ll explore the potential of LLMs to empower Networking Operations. No AI/ML knowledge is required.\nFor the Busy People - TL;DR For the Series LLM demonstrated significant promise in assisting with IT and networking configuration management and troubleshooting tasks. Human engineers are irreplaceable in the AI-driven landscape, as their technical expertise is essential for accurately conveying intentions to and guiding ChatGPT. A conversational approach to configuration management offers a more intuitive and user-friendly alternative than traditional automation tools. The integration of Function Calls and RAG plays a crucial role in minimizing hallucinations and enhancing the accuracy of configurations. Developing a robust validation pipeline for models is essential, given the potential for hallucinations and the inherent inconsistencies in LLMs. Treating LLMs as software development tools rather than chatbots is crucial. Understanding how to integrate them with external software will enhance the user experience and unlock a broader range of use cases. The rise of domain-specific LLMs, such as Large Vision Models, is anticipated to be a significant trend. While not everyone will be involved in their development, their application will become widespread across various fields. Introduction In this opening chapter, we\u0026rsquo;ll outline our mission the topics we intend to cover, and provide a high-level overview. Additionally, we\u0026rsquo;ll address some frequently asked questions.\nGiven my background in Cisco ACI, it will be the focus of our demonstrations. We will utilize the ChatGPT model, specifically \u0026ldquo;GPT-4\u0026rdquo;, for all demonstrations.\nMission The primary objective of this exploration is to assess the effectiveness of LLMs in managing networks without generating inaccurate or misleading information (commonly referred to as \u0026lsquo;hallucinations\u0026rsquo;)\nOur approach will begin with basic use cases, gradually increasing in complexity. The application of LLMs will guide all networking configuration changes, with inputs provided in plain English. Instead of relying on graphical user interfaces, our interaction will be purely conversational\nTopics To Be Covered Explore the fundamentals of instruction formulation, function invocation, context understanding, and prompt crafting in ChatGPT. Investigating ChatGPT\u0026rsquo;s ability to execute function calls for API interactions within an ACI environment. Analyzing ChatGPT\u0026rsquo;s responses to diverse queries and examining ways to refine them. Explore RAG (Retrieval Augmented Generation) for real-time knowledge retrieval to assist with network configurations. In future blogs, we will further look into more advanced LLM topics, such as fine-tuning LLMs and pre-training a model from scratch.\nEnvironment Setup and High-Level Flow We\u0026rsquo;ll have an ACI Simulator in the environment to interact with. We\u0026rsquo;ll create a small agent as the middleware that handles user input, communicates with ChatGPT, and makes API calls to the APIC simulator.\nFrequently Asked Questions Will network engineers become obsolete due to the evolution of LLMs?\nNo, network engineers will not become obsolete with the advent of LLMs. Our expert-level knowledge will become increasingly vital. The critical shift will be robust communication and expression skills, essential for effectively training, guiding, and educating LLMs using precise language.\nNetworking is a unique domain populated with proprietary information. This contrasts with the more open nature of general programming languages (Python, C, JS…etc).\nAdditionally, networking alone encompasses a variety of technologies (such as Firewalls, Routers, and Load Balancers), each with its specific hardware, capabilities, and firmware features. This complexity presents a significant challenge for any LLM to navigate successfully.\nTherefore, for LLMs to be truly effective and beneficial in networking, they require substantial knowledge input from human experts. By infusing LLMs with this expertise, they, in turn, can become powerful tools that augment and enhance our capabilities in network management.\nHow will LLMs impact network engineers ?\nLLMs will become a powerful aid to us, similar to their impact in other domains. While the intricacies of network design and intention remain too complex for LLMs to replace, they will significantly streamline tasks like routine network configuration changes. These tasks will become simpler, safer, more transparent, and eventually human language-driven. This advancement will likely enhance today\u0026rsquo;s Infrastructure as Code (IaC) practices. LLM can also act as an abstraction layer on top of IaC and interface directly with humans.\nAdditionally, network operations, troubleshooting, information gathering, and real-time action-taking will become more efficient as LLMs are user-friendly and can process complex requests. Over time, the role of the network engineer will gradually evolve from being technically oriented to being more aligned with business objectives, allowing for a greater focus on designing robust, resilient, extensible, and flexible networks.\nDesign to automate - The more a network adheres to a design pattern, the easier it will be for AI and LLMs to manage and maintain.\nQ: How is this different from network automations?\nAI/LLM offers several advantages over conventional automation tools like Ansible, Terraform, or Python-based scripts:\nA human-friendly natural language interface requires no automation skills to perform automated tasks.\nLLM can access a real-time knowledge base for informed decision-making and provide relevant recommendations as necessary.\nLLM can also engage in interactive dialogues, offering users insights into the implementation process of a task.\nLLM can reason and adapt to their environment when errors occur. For instance, they can correct typos in user input, unlike tools like Ansible or Terraform, which would report an error.\nLLM can analyze network topologies, providing an extra safety net for assessing the impact of a configuration change.\nDo network engineers need to pick up AI skills?\nNetwork engineers don\u0026rsquo;t necessarily need to master AI/ML algorithms, but acquiring skills that leverage AI technology is beneficial. This includes learning LLM prompt engineering, acquiring basic Python knowledge, and understanding APIs. Viewing tools like ChatGPT as development tools rather than a product is crucial. Otherwise, you\u0026rsquo;ll always be disappointed. This series will demonstrate how I apply ACI/Python knowledge to enhance ChatGPT\u0026rsquo;s performance.\nMost importantly, understanding the nuances of networking is crucial. While LLMs can readily acquire common and generic knowledge, the subtleties that stem from real-world experience are more complex to grasp. This is similar to how we can quickly learn generic networking concepts, but it takes time to grasp how such knowledge applies to specific networking environments.\nSome of the answers above might not be obvious, but hopefully, they’ll become clearer at the end of this series.\nOne Last Thought As we witness the ongoing evolution of Large Language Models, the boundaries of their capabilities are largely defined by the extent of our imagination. The key lies in our ability to offer precise guidance. The potential of LLMs is vast, but it hinges on our skillful interaction and thoughtful input.\nSee you in the next article: Networking and LLM in the Age of AI - Pt II: Exploring Basic Interactions\n","permalink":"http://zhangineer.net/posts/2023-10-07-networking-and-llm-pt1/","summary":"A series to explore how to leverage LLM for networking tasks\nThe rise of chatGPT and large language models (LLM) has opened up the possibility of transforming various domains. However, networking remains largely unexplored.\nIn this series, we\u0026rsquo;ll explore the potential of LLMs to empower Networking Operations. No AI/ML knowledge is required.\nFor the Busy People - TL;DR For the Series LLM demonstrated significant promise in assisting with IT and networking configuration management and troubleshooting tasks.","title":"Networking and LLM in the Age of AI — Pt. I: The Exploration Begins"}]